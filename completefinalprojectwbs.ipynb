{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QED137/cineBoat/blob/main/completefinalprojectwbs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnUGobrLb6JO"
      },
      "source": [
        "# **The project outline**\n",
        "The Multimodal RAG for Film and Entertainment project  aims to build an intelligent system that provides insights and recommendations about movies and TV shows by integrating a knowledge graph with multimodal data. It combines structured relationships (e.g., directors, genres, cast) from a Neo4j knowledge graph with embeddings from trailers, reviews, and metadata for enhanced retrieval and contextualized responses.\n",
        "##Core Features:\n",
        "* Integrate structured data using a Neo4j knowledge graph.\n",
        "* Process multimodal unstructured data (text, video, audio) into embeddings.\n",
        "* Use a Retrieval-Augmented Generation (RAG) pipeline for intelligent\n",
        "   recommendations and insights.\n",
        "\n",
        "### Tool and Technology\n",
        "\n",
        "| Component\t| Tools/Technologies |\n",
        "|------------|------------------- |\n",
        "|Knowledge Graph\t| Neo4j, Cypher|\n",
        "|Text Embeddings |\tHugging Face (BERT, GPT), OpenAI|\n",
        "|Video Embeddings|\tCLIP, VideoMAE|\n",
        "|Vector Search\t|Pinecone, FAISS, Weaviate|\n",
        "|Visualization\t|Neo4j Browser, NetworkX, matplotlib|\n",
        "|Language Generation |\tGPT-4, Hugging Face Transformers|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILrcv9g0b49t"
      },
      "source": [
        "## Work Flow\n",
        "Step-by-Step Implementation\n",
        "1. **Define Scope and Data Sources**\n",
        "* Target Output: Deliver contextualized recommendations (e.g., \"Find movies\n",
        " like Inception that share a similar visual style and have a compelling plot\").\n",
        "* Data Requirements:\n",
        "* Structured Data: Movies, TV shows, directors, genres, cast relationships.\n",
        "* Unstructured Data:\n",
        "   *  Video: Trailers, key scenes.\n",
        "   * Text: Reviews, summaries, audience feedback.\n",
        "   * Metadata: IMDb/Rotten Tomatoes scores, release year.\n",
        "2. **Set Up Knowledge Graph (Neo4j)**\n",
        "\n",
        "   a. Install neo4js\n",
        "    * Install Neo4j locally or use Neo4j AuraDB for a cloud-hosted option.\n",
        "   b. Define Schema:\n",
        "     * Nodes: Movie, Director, Actor, Genre.\n",
        "     *Relationships:\n",
        "\n",
        "        * (:Movie)-[:DIRECTED_BY]->(:Director)\n",
        "\n",
        "        * (:Movie)-[:HAS_GENRE]->(:Genre)\n",
        "        \n",
        "        *  (:Movie)-[:FEATURES]->(:Actor)\n",
        "\n",
        "  c. Populate Data\n",
        "\n",
        "3. **Process Multimodal Data**\n",
        "\n",
        "   a. Text Data (Reviews, Metadata)\n",
        "   \n",
        "      Use embeddings from transformer models like BERT or OpenAI for feature extraction\n",
        "\n",
        "   b. Video Data (Trailers)\n",
        "      Extract video and audio embeddings using models like CLIP or VideoMAE:\n",
        "\n",
        "   c. Audio Data (Soundtracks, Dialogues)\n",
        "     Use models like OpenL3 or Wav2Vec for embedding extraction.   \n",
        "\n",
        "4. Build RAG Workflow\n",
        "\n",
        "     a. Retrieve Structured Data:\n",
        "     \n",
        "     * Use Neo4j to query relationships and basic metadata.\n",
        "\n",
        "  b. Retrieve Unstructured Data:\n",
        "    * Use a vector database (e.g., Pinecone, Weaviate, or FAISS) to perform similarity searches on multimodal embeddings.\n",
        "\n",
        "  c. Combine Results:\n",
        "  \n",
        "     * Merge Neo4j results with vector database results in a unified response.\n",
        "        \n",
        "     * Example: Find movies similar to Inception using graph metadata and embedding similarity.\n",
        "\n",
        "  d. Generate Contextual Responses:\n",
        "     \n",
        "     * Use a language model like GPT-4 for natural language output:     \n",
        "5.** User Interaction**\n",
        "  \n",
        "  a. Visualization and Exploration\n",
        "  Neo4j Browser:\n",
        "   \n",
        "   * Visualize nodes and relationships directly in the Neo4j interface.\n",
        "  \n",
        "  b. Local Interface:\n",
        "     \n",
        "     * Use Jupyter Notebooks for an interactive educational experience.\n",
        "        \n",
        "     * Include Python libraries like matplotlib or plotly for graph visualization.\n",
        "\n",
        "## **Workflow Demonstration**\n",
        "\n",
        "1.   Input a query like \"Find action movies directed by James Cameron with a tone similar to Avatar.\"\n",
        "\n",
        "2.   Query Neo4j for action movies by James Cameron.\n",
        "\n",
        "3. Search vector embeddings for movies with similar visual and auditory tone.\n",
        "\n",
        "4. Combine and display the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF7rPE3Ik9Z-"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKLZ9oADk9-G"
      },
      "source": [
        "# Essential Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IUFqPTaRk7TF",
        "outputId": "df9a51d4-68aa-4438-ad92-2548e7cb4ddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.3/312.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\n",
            "added 22 packages in 3s\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install -q neo4j pandas\n",
        "\n",
        "!pip install -q python-dotenv\n",
        "!pip install -q  neo4j\n",
        "!pip install -q langchain_community\n",
        "!pip install -q streamlit neo4j openai\n",
        "!pip install -q keybert transformers\n",
        "!pip install -q keybert\n",
        "!pip install -q streamlit-chat\n",
        "!pip install -q python-dotenv\n",
        "!npm install -qqq -U localtunnel\n",
        "!pip install -q langchain_openai\n",
        "!pip install -q langchain openai\n",
        "!pip install -q fuzzywuzzy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm audit report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9Q5DLrBxG8o",
        "outputId": "0ffba0fd-5553-4cfc-ea92-6b778fab1ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\u001b[1m# npm audit report\u001b[22m\n",
            "\n",
            "\u001b[1maxios\u001b[22m  <=0.29.0\n",
            "Severity: \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m\n",
            "\u001b[1mAxios Cross-Site Request Forgery Vulnerability\u001b[22m - https://github.com/advisories/GHSA-wf5p-g6vw-rhxx\n",
            "\u001b[1maxios Requests Vulnerable To Possible SSRF and Credential Leakage via Absolute URL\u001b[22m - https://github.com/advisories/GHSA-jr5f-v2jv-69x6\n",
            "\u001b[33m\u001b[1mfix available\u001b[22m\u001b[39m via `npm audit fix --force`\n",
            "Will install localtunnel@1.8.3, which is a breaking change\n",
            "\u001b[2mnode_modules/axios\u001b[22m\n",
            "  \u001b[1mlocaltunnel\u001b[22m  >=1.9.0\n",
            "  Depends on vulnerable versions of \u001b[1maxios\u001b[22m\n",
            "  \u001b[2mnode_modules/localtunnel\u001b[22m\n",
            "\n",
            "2 \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Essential Imports"
      ],
      "metadata": {
        "id": "RgGxdg9atgkf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oqhxlft_tdL"
      },
      "outputs": [],
      "source": [
        "from neo4j import GraphDatabase\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "\n",
        "# Warning control\n",
        "import warnings\n",
        "import requests\n",
        "from requests.auth import HTTPBasicAuth\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "from neo4j import GraphDatabase\n",
        "from google.colab import userdata\n",
        "import streamlit as st\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up environement"
      ],
      "metadata": {
        "id": "g9vdw1thpTix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### On colab\n",
        "If one is using the code only colab then setting up this envirnement with your own keys and passwords."
      ],
      "metadata": {
        "id": "OZb_yHxJpkZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k0pBGzBupwM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environement for Streamlit app\n",
        "Write your own secrets.toml file an then upload it to colab by running the folloiwng caommand. If one want to use namimg convention similar to this code then write passowrds and key in xour secrets.py file like the following. In your  **secrets.toml** file"
      ],
      "metadata": {
        "id": "OHxHXrAFp0Ht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.streamlit\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # Use the upload dialog to select `secrets.toml`\n",
        "!mv secrets.toml ~/.streamlit/ #strealit takes paswwords and keys from here"
      ],
      "metadata": {
        "id": "FKftQXGUp6um",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "7084a33e-a222-43b2-abbc-6772cb70d0b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8be541d4-8d63-4999-bb09-7c26775b4e15\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8be541d4-8d63-4999-bb09-7c26775b4e15\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'secrets.toml': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set the passwords and enviroment for streamlit app"
      ],
      "metadata": {
        "id": "ojKRqxJpsZ5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uri = st.secrets[\"NEO4J_URI\"]\n",
        "username = st.secrets[\"NEO4J_USERNAME\"]\n",
        "password = st.secrets[\"NEO4J_PASSWORD\"]\n",
        "TMDB_API_KEY = st.secrets[\"TMDB_API\"]\n",
        "database = st.secrets[\"NEO4J_DATABASE\"]\n",
        "openai_key = st.secrets[\"OPENAI_API_KEY\"]"
      ],
      "metadata": {
        "id": "oWTAwnkNsY8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up NEO4j database"
      ],
      "metadata": {
        "id": "x3v7Ofx-s9yo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp4LLHb3lFVd",
        "outputId": "094d9e92-ed1f-4d9f-b3f2-bd9771a5f394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to Neo4j from Colab!\n"
          ]
        }
      ],
      "source": [
        "#setting connection to neo4j\n",
        "\n",
        "try:\n",
        "    driver = GraphDatabase.driver(uri, auth=(username, password))\n",
        "    with driver.session() as session:\n",
        "        result = session.run(\"RETURN 'Connected to Neo4j from Colab!' AS message\")\n",
        "        for record in result:\n",
        "            print(record[\"message\"])\n",
        "except Exception as e:\n",
        "    print(\"Failed to connect to Neo4j:\", e)\n",
        "finally:\n",
        "    driver.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6VIJ0pOQYvh"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "\n",
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2IIvSwPRBP2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a29932d-64d8-49ef-d4ab-1e9cbc0e33be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-3b23eb52ddee>:2: LangChainDeprecationWarning: The class `Neo4jGraph` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :class:`~langchain-neo4j` and import as `from :class:`~langchain_neo4j import Neo4jGraph``.\n",
            "  kg = Neo4jGraph(\n"
          ]
        }
      ],
      "source": [
        "#Initialize a knowledge graph instance using LangChain's Neo4j integration\n",
        "kg = Neo4jGraph(\n",
        "    uri, username, password, database\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wl8i76WCRUTX"
      },
      "outputs": [],
      "source": [
        "cypher = \"\"\"\n",
        "  MATCH (n)\n",
        "  RETURN count(n)\n",
        "  \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wA1-ldMRYgt",
        "outputId": "bb9abc13-4b27-4b3d-fb9e-11743801a0da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'count(n)': 3678}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "result = kg.query(cypher)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3c0VS8hTqaR"
      },
      "outputs": [],
      "source": [
        "#aliases like sql\n",
        "cypher = \"\"\"\n",
        "  MATCH (n)\n",
        "\n",
        "  RETURN count(n) AS numberOfNodes\n",
        "  \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrRU1pc1TsxU",
        "outputId": "c9bc6261-f0e3-4f55-c5b9-5bbad1a595c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'numberOfNodes': 3678}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "result = kg.query(cypher)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJDVDCqCzRWg",
        "outputId": "24d7f123-8c8e-4883-db09-5c25f8ffa3a1",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'nineties.title': 'Harry Potter and the Deathly Hallows: Part 2'},\n",
              " {'nineties.title': 'Office Christmas Party'},\n",
              " {'nineties.title': 'The Neon Demon'},\n",
              " {'nineties.title': 'Dangal'},\n",
              " {'nineties.title': '10 Cloverfield Lane'},\n",
              " {'nineties.title': 'Finding Dory'},\n",
              " {'nineties.title': \"Miss Peregrine's Home for Peculiar Children\"},\n",
              " {'nineties.title': 'Divergent'},\n",
              " {'nineties.title': 'Mike and Dave Need Wedding Dates'},\n",
              " {'nineties.title': 'Boyka: Undisputed IV'}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "## some queries using cypher\n",
        "cypher = \"\"\"\n",
        "  MATCH (nineties:Movie)\n",
        "  WHERE nineties.year >= 2006\n",
        "    AND nineties.year < 2020\n",
        "  RETURN nineties.title limit 10\n",
        "  \"\"\"\n",
        "kg.query(cypher)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cypher =\"\"\"\n",
        "Match (m:Movie)\n",
        "where m.year <= 2006\n",
        "Return m.year limit 10\n",
        "\"\"\"\n",
        "kg.query(cypher)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDvOit3UFZ5p",
        "outputId": "a755e8d8-2ecf-4514-955f-314ec9ef8f72",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'m.year': 2006},\n",
              " {'m.year': 2006},\n",
              " {'m.year': 2006},\n",
              " {'m.year': 2006},\n",
              " {'m.year': 2006},\n",
              " {'m.year': 2006},\n",
              " {'m.year': 2006},\n",
              " {'m.year': 2006},\n",
              " {'m.year': 2006},\n",
              " {'m.year': 2006}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cypher =\"\"\"\n",
        "Match (m:Movie)\n",
        "where m.year <= 2006\n",
        "Return m.year, m.title\n",
        "\"\"\"\n",
        "kg.query(cypher)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNnIMBJQGVB_",
        "outputId": "8b744663-2cd7-4477-954e-47e84bc511dd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'m.year': 2006, 'm.title': 'Casino Royale'},\n",
              " {'m.year': 2006, 'm.title': 'Cars'},\n",
              " {'m.year': 2006, 'm.title': \"Pan's Labyrinth\"},\n",
              " {'m.year': 2006, 'm.title': 'Apocalypto'},\n",
              " {'m.year': 2006, 'm.title': 'The Host'},\n",
              " {'m.year': 2006, 'm.title': 'Children of Men'},\n",
              " {'m.year': 2006, 'm.title': 'The Devil Wears Prada'},\n",
              " {'m.year': 2006, 'm.title': 'The Fast and the Furious: Tokyo Drift'},\n",
              " {'m.year': 2006, 'm.title': 'Step Up'},\n",
              " {'m.year': 2006, 'm.title': 'Silent Hill'},\n",
              " {'m.year': 2006, 'm.title': 'Marie Antoinette'},\n",
              " {'m.year': 2006, 'm.title': 'The Lives of Others'},\n",
              " {'m.year': 2006, 'm.title': 'A Good Year'},\n",
              " {'m.year': 2006, 'm.title': 'Deja Vu'},\n",
              " {'m.year': 2006, 'm.title': 'The Break-Up'},\n",
              " {'m.year': 2006, 'm.title': 'Idiocracy'},\n",
              " {'m.year': 2006, 'm.title': 'Little Miss Sunshine'},\n",
              " {'m.year': 2006, 'm.title': \"She's the Man\"},\n",
              " {'m.year': 2006, 'm.title': 'X-Men: The Last Stand'},\n",
              " {'m.year': 2006, 'm.title': 'The Pursuit of Happyness'},\n",
              " {'m.year': 2006, 'm.title': 'Blood Diamond'},\n",
              " {'m.year': 2006, 'm.title': 'Happy Feet'},\n",
              " {'m.year': 2006, 'm.title': 'The Illusionist'},\n",
              " {'m.year': 2006, 'm.title': 'The Da Vinci Code'},\n",
              " {'m.year': 2006, 'm.title': 'Lady in the Water'},\n",
              " {'m.year': 2006, 'm.title': 'The Fountain'},\n",
              " {'m.year': 2006, 'm.title': 'Rescue Dawn'},\n",
              " {'m.year': 2006, 'm.title': 'Inside Man'},\n",
              " {'m.year': 2006, 'm.title': 'Rocky Balboa'},\n",
              " {'m.year': 2006, 'm.title': 'The Hills Have Eyes'},\n",
              " {'m.year': 2006, 'm.title': 'Mission: Impossible III'},\n",
              " {'m.year': 2006, 'm.title': 'Babel'},\n",
              " {'m.year': 2006, 'm.title': 'The Fall'},\n",
              " {'m.year': 2006, 'm.title': 'Snakes on a Plane'},\n",
              " {'m.year': 2006, 'm.title': 'Slither'},\n",
              " {'m.year': 2006, 'm.title': 'Perfume: The Story of a Murderer'},\n",
              " {'m.year': 2006, 'm.title': 'Superman Returns'},\n",
              " {'m.year': 2006, 'm.title': 'Talladega Nights: The Ballad of Ricky Bobby'},\n",
              " {'m.year': 2006, 'm.title': 'Lucky Number Slevin'},\n",
              " {'m.year': 2006, 'm.title': 'Inland Empire'},\n",
              " {'m.year': 2006, 'm.title': '300'},\n",
              " {'m.year': 2006, 'm.title': 'The Prestige'},\n",
              " {'m.year': 2006, 'm.title': \"Pirates of the Caribbean: Dead Man's Chest\"},\n",
              " {'m.year': 2006, 'm.title': 'The Departed'}]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZJm5LZD0NaK",
        "outputId": "3b75cade-f109-4ece-f76a-6a42f3eeb466"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'numberOfMovies': 999}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#number of movie\n",
        "cypher = \"\"\"\n",
        "  MATCH (m:Movie)\n",
        "  RETURN count(m) AS numberOfMovies\n",
        "  \"\"\"\n",
        "kg.query(cypher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inewiXqaTfXx"
      },
      "source": [
        "### Playing with neo4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MJJSSAXTnao"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rA_jP4ZTiRO",
        "outputId": "89e51c12-1c1b-4cc0-9a51-3098a03926ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The movie 'Inception' exists in the database.\n"
          ]
        }
      ],
      "source": [
        "movie_title = \"Inception\"\n",
        "cypher = f\"\"\"\n",
        "MATCH (m:Movie {{title: '{movie_title}'}})\n",
        "RETURN m.title AS title\n",
        "\"\"\"\n",
        "result = kg.query(cypher)\n",
        "if result:\n",
        "    print(f\"The movie '{movie_title}' exists in the database.\")\n",
        "else:\n",
        "    print(f\"The movie '{movie_title}' is not in the database.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szq2tpzYgxSP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QupvoVKUInhK"
      },
      "source": [
        "# Downlaoding Kaggle data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXQ6rGnGJw7d",
        "outputId": "7d9d99c3-2a88-4a31-db54-ff85a2161871"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "j-L6zyJiLkhq",
        "outputId": "6ffea087-7bec-4240-f716-a919869e995b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4cadeabc-b5d1-4bbc-bcb3-04b975fe28e1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4cadeabc-b5d1-4bbc-bcb3-04b975fe28e1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"janmajaykumar\",\"key\":\"303ae1d6d6dd04b357aa7c364b59fb75\"}'}"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Upload kaggle.json here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "v_cAvp8jLs9B"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyZka_0RLVg5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create the Kaggle directory\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "\n",
        "# Move the kaggle.json file to the .kaggle directory\n",
        "!mv kaggle.json /root/.kaggle/\n",
        "\n",
        "# Change permissions\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "H_Z4PJxUNi4J",
        "outputId": "486959d1-cbc0-4af4-8338-f4e554a3e984"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading the-movies-dataset.zip to /content\n",
            " 99% 226M/228M [00:11<00:00, 20.9MB/s]\n",
            "100% 228M/228M [00:11<00:00, 20.9MB/s]\n",
            "Archive:  the-movies-dataset.zip\n",
            "  inflating: credits.csv             \n",
            "  inflating: keywords.csv            \n",
            "  inflating: links.csv               \n",
            "  inflating: links_small.csv         \n",
            "  inflating: movies_metadata.csv     \n",
            "  inflating: ratings.csv             \n",
            "  inflating: ratings_small.csv       \n"
          ]
        }
      ],
      "source": [
        "# Download movie dataset\n",
        "!kaggle datasets download -d rounakbanik/the-movies-dataset\n",
        "\n",
        "# Unzip the downloaded dataset\n",
        "!unzip the-movies-dataset.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "collapsed": true,
        "id": "xQuvSIm5K3DQ",
        "outputId": "c2653cf5-c06b-4fd9-e9db-ecd7bf858e1f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"link_small\",\n  \"rows\": 45476,\n  \"fields\": [\n    {\n      \"column\": \"cast\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 43019,\n        \"samples\": [\n          \"[{'cast_id': 2, 'character': 'Lazar Peacock/Sabata', 'credit_id': '52fe4bca9251416c7510e195', 'gender': 2, 'id': 20581, 'name': 'Jack Betts', 'order': 0, 'profile_path': '/f03shMGYcbPG2EyjkIVAR0YA1RA.jpg'}, {'cast_id': 3, 'character': 'Blonde', 'credit_id': '52fe4bca9251416c7510e199', 'gender': 0, 'id': 100683, 'name': 'Franco Borelli', 'order': 1, 'profile_path': None}, {'cast_id': 4, 'character': 'Roger Murdock', 'credit_id': '52fe4bca9251416c7510e19d', 'gender': 2, 'id': 30898, 'name': 'Gordon Mitchell', 'order': 2, 'profile_path': '/szzvsqfFlkHBUJEiZtRquIhxHqn.jpg'}, {'cast_id': 5, 'character': 'Maya', 'credit_id': '52fe4bca9251416c7510e1a1', 'gender': 1, 'id': 30902, 'name': 'Simonetta Vitelli', 'order': 3, 'profile_path': '/jMnRUMgLV3l6lyB26bd8t9b11m5.jpg'}]\",\n          \"[{'cast_id': 2, 'character': 'Charles', 'credit_id': '590cf25dc3a36864c60039ff', 'gender': 2, 'id': 11276, 'name': 'Tim Pigott-Smith', 'order': 1, 'profile_path': '/yC5fQ2HYxzD5JqnXZKMJ6giExrU.jpg'}, {'cast_id': 3, 'character': 'Kate Middleton', 'credit_id': '590cf268c3a36864fc003a3b', 'gender': 1, 'id': 115679, 'name': 'Charlotte Riley', 'order': 2, 'profile_path': '/pkiZKysfb0oXvaBBm6zWQkWSvVu.jpg'}, {'cast_id': 4, 'character': 'William', 'credit_id': '590cf2769251414e85003b16', 'gender': 2, 'id': 31739, 'name': 'Oliver Chris', 'order': 3, 'profile_path': '/xTnUMtP5MREaHD86XfJ5mYibawq.jpg'}, {'cast_id': 5, 'character': 'Prime Minister Tristram Evans', 'credit_id': '590cf284c3a36864c6003a15', 'gender': 2, 'id': 47933, 'name': 'Adam James', 'order': 4, 'profile_path': '/4dSIRIEEnK2tC1OrgjEykUvOeFw.jpg'}, {'cast_id': 7, 'character': 'Harry', 'credit_id': '590cf2bd9251414e8d0038d1', 'gender': 0, 'id': 1409393, 'name': 'Richard Goulding', 'order': 6, 'profile_path': '/3vM6hrfcU4NLBvWoRxyo8nkPsDU.jpg'}, {'cast_id': 8, 'character': 'Coottsey', 'credit_id': '590cf2e5c3a36864ec0036e3', 'gender': 2, 'id': 1428460, 'name': 'Max Bennett', 'order': 7, 'profile_path': '/fthD8U3aGnQioWAiwvFPcdDQJRV.jpg'}, {'cast_id': 9, 'character': 'Jess', 'credit_id': '590ef2e29251414ead01c7d5', 'gender': 0, 'id': 1595457, 'name': 'Tamara Lawrance', 'order': 8, 'profile_path': None}, {'cast_id': 10, 'character': 'Camilla', 'credit_id': '590ef2f79251414eca01c988', 'gender': 1, 'id': 192933, 'name': 'Margot Leicester', 'order': 9, 'profile_path': '/M2PEeYUdkrd4VjI1D0lsHbiG8t.jpg'}, {'cast_id': 11, 'character': 'James Reiss', 'credit_id': '590ef30fc3a36864d401e229', 'gender': 2, 'id': 15740, 'name': 'Tim McMullan', 'order': 10, 'profile_path': '/8se9JhmD9LE6tiibkGiV51M8rdD.jpg'}, {'cast_id': 12, 'character': 'Mrs Stevens', 'credit_id': '590ef326c3a36864fc01d3f7', 'gender': 0, 'id': 62968, 'name': 'Priyanga Burford', 'order': 11, 'profile_path': '/yTxLb30QwUAs5aoErhnYsnGawG5.jpg'}, {'cast_id': 13, 'character': 'Diana', 'credit_id': '590ef334c3a36864fc01d3ff', 'gender': 1, 'id': 1528819, 'name': 'Katie Brayben', 'order': 12, 'profile_path': '/m7oOBu4cfamQ9wixTyWXNaH9sgn.jpg'}, {'cast_id': 14, 'character': 'Archbishop of Canterbury', 'credit_id': '590ef372c3a368650a01c818', 'gender': 2, 'id': 940, 'name': 'John Shrapnel', 'order': 13, 'profile_path': '/nDIK01IoVNx7cfYOrKqGugItqO9.jpg'}, {'cast_id': 15, 'character': 'Spencer', 'credit_id': '590ef37e9251414ead01c82c', 'gender': 0, 'id': 1455682, 'name': 'Parth Thakerar', 'order': 14, 'profile_path': None}]\",\n          \"[{'cast_id': 1, 'character': 'Himself', 'credit_id': '52fe4a9bc3a368484e15d20d', 'gender': 0, 'id': 1078721, 'name': 'Armand Leroi', 'order': 0, 'profile_path': None}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"crew\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 44669,\n        \"samples\": [\n          \"[{'credit_id': '52fe461ac3a36847f80eccfd', 'department': 'Directing', 'gender': 2, 'id': 107463, 'job': 'Director', 'name': 'Del Tenney', 'profile_path': None}, {'credit_id': '52fe461ac3a36847f80ecd13', 'department': 'Writing', 'gender': 0, 'id': 107464, 'job': 'Screenplay', 'name': 'Richard Hilliard', 'profile_path': None}, {'credit_id': '52fe461ac3a36847f80ecd19', 'department': 'Production', 'gender': 2, 'id': 107463, 'job': 'Producer', 'name': 'Del Tenney', 'profile_path': None}]\",\n          \"[{'credit_id': '52fe45439251416c9102c5bd', 'department': 'Directing', 'gender': 2, 'id': 93975, 'job': 'Director', 'name': 'Lewis Allen', 'profile_path': None}, {'credit_id': '52fe45439251416c9102c5c3', 'department': 'Writing', 'gender': 0, 'id': 111580, 'job': 'Novel', 'name': 'Tiffany Thayer', 'profile_path': None}, {'credit_id': '52fe45439251416c9102c5c9', 'department': 'Writing', 'gender': 2, 'id': 10148, 'job': 'Writer', 'name': 'Warren Duff', 'profile_path': None}, {'credit_id': '52fe45439251416c9102c5cf', 'department': 'Production', 'gender': 2, 'id': 50311, 'job': 'Producer', 'name': 'Robert Fellows', 'profile_path': None}, {'credit_id': '52fe45439251416c9102c5d5', 'department': 'Sound', 'gender': 2, 'id': 26026, 'job': 'Original Music Composer', 'name': 'Victor Young', 'profile_path': None}, {'credit_id': '52fe45439251416c9102c5db', 'department': 'Camera', 'gender': 2, 'id': 8620, 'job': 'Director of Photography', 'name': 'John F. Seitz', 'profile_path': '/6hvivkKP5H5NpPcAViAfUMFgqsu.jpg'}, {'credit_id': '52fe45439251416c9102c5e1', 'department': 'Editing', 'gender': 2, 'id': 30013, 'job': 'Editor', 'name': 'LeRoy Stone', 'profile_path': None}]\",\n          \"[{'credit_id': '52fe45319251416c7504eab9', 'department': 'Writing', 'gender': 2, 'id': 14999, 'job': 'Screenplay', 'name': 'George A. Romero', 'profile_path': '/zNP7wdy48eNNJAAmM0pYbSelUAd.jpg'}, {'credit_id': '52fe45319251416c7504ea8b', 'department': 'Directing', 'gender': 2, 'id': 14999, 'job': 'Director', 'name': 'George A. Romero', 'profile_path': '/zNP7wdy48eNNJAAmM0pYbSelUAd.jpg'}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 112443,\n        \"min\": 2,\n        \"max\": 469172,\n        \"num_unique_values\": 45432,\n        \"samples\": [\n          43942,\n          30139,\n          85389\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "link_small"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0126e2cc-0681-4641-8360-77ed4a547988\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cast</th>\n",
              "      <th>crew</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[{'cast_id': 14, 'character': 'Woody (voice)',...</td>\n",
              "      <td>[{'credit_id': '52fe4284c3a36847f8024f49', 'de...</td>\n",
              "      <td>862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[{'cast_id': 1, 'character': 'Alan Parrish', '...</td>\n",
              "      <td>[{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...</td>\n",
              "      <td>8844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[{'cast_id': 2, 'character': 'Max Goldman', 'c...</td>\n",
              "      <td>[{'credit_id': '52fe466a9251416c75077a89', 'de...</td>\n",
              "      <td>15602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[{'cast_id': 1, 'character': \"Savannah 'Vannah...</td>\n",
              "      <td>[{'credit_id': '52fe44779251416c91011acb', 'de...</td>\n",
              "      <td>31357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[{'cast_id': 1, 'character': 'George Banks', '...</td>\n",
              "      <td>[{'credit_id': '52fe44959251416c75039ed7', 'de...</td>\n",
              "      <td>11862</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0126e2cc-0681-4641-8360-77ed4a547988')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0126e2cc-0681-4641-8360-77ed4a547988 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0126e2cc-0681-4641-8360-77ed4a547988');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cb98cbc2-e542-4746-82be-f8fb17e42d04\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cb98cbc2-e542-4746-82be-f8fb17e42d04')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cb98cbc2-e542-4746-82be-f8fb17e42d04 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                cast  \\\n",
              "0  [{'cast_id': 14, 'character': 'Woody (voice)',...   \n",
              "1  [{'cast_id': 1, 'character': 'Alan Parrish', '...   \n",
              "2  [{'cast_id': 2, 'character': 'Max Goldman', 'c...   \n",
              "3  [{'cast_id': 1, 'character': \"Savannah 'Vannah...   \n",
              "4  [{'cast_id': 1, 'character': 'George Banks', '...   \n",
              "\n",
              "                                                crew     id  \n",
              "0  [{'credit_id': '52fe4284c3a36847f8024f49', 'de...    862  \n",
              "1  [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...   8844  \n",
              "2  [{'credit_id': '52fe466a9251416c75077a89', 'de...  15602  \n",
              "3  [{'credit_id': '52fe44779251416c91011acb', 'de...  31357  \n",
              "4  [{'credit_id': '52fe44959251416c75039ed7', 'de...  11862  "
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "link_small= pd.read_csv(\"/content/credits.csv\")\n",
        "link_small.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3oyRIA390Gk",
        "outputId": "eb9dcb8d-566f-4480-ffc4-a71763a13a23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rishabjadhav/imdb-actors-and-movies?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 453M/453M [00:05<00:00, 90.4MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/rishabjadhav/imdb-actors-and-movies/versions/1\n"
          ]
        }
      ],
      "source": [
        "#another way of improting data from kaggle\n",
        "import kagglehub\n",
        "\n",
        "# Download the latest version of the dataset\n",
        "path = kagglehub.dataset_download(\"rishabjadhav/imdb-actors-and-movies\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCFCX4X3AxP4",
        "outputId": "0bf2ffb3-b4b3-4d96-8134-b341ac15931b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "combined.csv  names.csv  titles.csv\n",
            "combined.csv  names.csv  titles.csv\n"
          ]
        }
      ],
      "source": [
        "!ls {path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDCrkYcaBZRa",
        "outputId": "00532f51-fca4-430e-acbb-1461717f6e28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(546421, 5)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "csv_file_path = f\"{path}/combined.csv\"\n",
        "df_one = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Step 4: Display the DataFrame\n",
        "df_one.sample(19)\n",
        "df_one.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcY2qhCNDiGG"
      },
      "outputs": [],
      "source": [
        "df_one.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ImxNwDJ99_iL",
        "outputId": "49c32c76-ed29-4ded-acc2-98b9bd2c1f15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/imdb-dataset'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#one want to move the downlaoded file to the local drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# import shutil\n",
        "# shutil.move(path, '/content/drive/My Drive/imdb-dataset')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDg4PkNrN22n"
      },
      "outputs": [],
      "source": [
        "# #IMdb actor data set\n",
        "# !kaggle datasets download -d lsrishabjadhav/imdb-actors-and-movies\n",
        "# !!unzip the-movies-dataset.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qldww7jTN7o6"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwNk0R41N-iN"
      },
      "outputs": [],
      "source": [
        "df_movie_meta = pd.read_csv(\"/content/movies_metadata.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAL2jbVTPwWX"
      },
      "outputs": [],
      "source": [
        "df_rating=pd.read_csv(\"/content/ratings.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Igf9b_9hDTKv",
        "outputId": "45873972-627f-4eff-fb1c-0a764fcdb7f1",
        "collapsed": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_rating"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c0e58196-b905-4d1b-ab3e-533de3757728\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>110</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1425941529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>147</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1425942435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>858</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1425941523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1221</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1425941546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1246</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1425941556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0e58196-b905-4d1b-ab3e-533de3757728')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c0e58196-b905-4d1b-ab3e-533de3757728 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c0e58196-b905-4d1b-ab3e-533de3757728');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c8678559-5a4f-405f-ba6a-e1ae971e38d3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c8678559-5a4f-405f-ba6a-e1ae971e38d3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c8678559-5a4f-405f-ba6a-e1ae971e38d3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   userId  movieId  rating   timestamp\n",
              "0       1      110     1.0  1425941529\n",
              "1       1      147     4.5  1425942435\n",
              "2       1      858     5.0  1425941523\n",
              "3       1     1221     5.0  1425941546\n",
              "4       1     1246     5.0  1425941556"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_rating.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKv3SBPqQHHL"
      },
      "outputs": [],
      "source": [
        "df_keywords= pd.read_csv(\"/content/keywords.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cX9DSMSQz2j"
      },
      "outputs": [],
      "source": [
        "## reading data from anther file\n",
        "df_actor=pd.read_csv('/content/drive/MyDrive/imdb-dataset/combined.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rjYMHzw5-vWu",
        "outputId": "ef5c78dd-ce15-4662-ab06-506dfc2bfec5",
        "collapsed": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_actor"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3d08fb27-ae1e-476b-a3ff-a0e2790f8388\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>primaryName</th>\n",
              "      <th>birthYear</th>\n",
              "      <th>deathYear</th>\n",
              "      <th>primaryProfession</th>\n",
              "      <th>knownForTitle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fred Astaire</td>\n",
              "      <td>1899</td>\n",
              "      <td>1987.0</td>\n",
              "      <td>actor,miscellaneous,producer</td>\n",
              "      <td>The Towering Inferno</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lauren Bacall</td>\n",
              "      <td>1924</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>actress,soundtrack,archive_footage</td>\n",
              "      <td>To Have and Have Not</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Brigitte Bardot</td>\n",
              "      <td>1934</td>\n",
              "      <td>NaN</td>\n",
              "      <td>actress,music_department,producer</td>\n",
              "      <td>Contempt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>John Belushi</td>\n",
              "      <td>1949</td>\n",
              "      <td>1982.0</td>\n",
              "      <td>actor,writer,music_department</td>\n",
              "      <td>Saturday Night Live</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ingmar Bergman</td>\n",
              "      <td>1918</td>\n",
              "      <td>2007.0</td>\n",
              "      <td>writer,director,actor</td>\n",
              "      <td>Wild Strawberries</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546416</th>\n",
              "      <td>William Riva</td>\n",
              "      <td>1919</td>\n",
              "      <td>1999.0</td>\n",
              "      <td>set_decorator</td>\n",
              "      <td>The Paul Winchell Show</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546417</th>\n",
              "      <td>Frank J. Gaily</td>\n",
              "      <td>1915</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>sound_department</td>\n",
              "      <td>After Hours</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546418</th>\n",
              "      <td>Ben Ray Lujan</td>\n",
              "      <td>1972</td>\n",
              "      <td>NaN</td>\n",
              "      <td>archive_footage</td>\n",
              "      <td>CNN Newsroom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546419</th>\n",
              "      <td>Henry Lawfull</td>\n",
              "      <td>2006</td>\n",
              "      <td>NaN</td>\n",
              "      <td>actor</td>\n",
              "      <td>A Boy Called Christmas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546420</th>\n",
              "      <td>Apsara Rani</td>\n",
              "      <td>1996</td>\n",
              "      <td>NaN</td>\n",
              "      <td>actress</td>\n",
              "      <td>Dangerous</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>546421 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d08fb27-ae1e-476b-a3ff-a0e2790f8388')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3d08fb27-ae1e-476b-a3ff-a0e2790f8388 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3d08fb27-ae1e-476b-a3ff-a0e2790f8388');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8d1704e1-30c6-49a6-9703-b2270d09c151\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d1704e1-30c6-49a6-9703-b2270d09c151')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8d1704e1-30c6-49a6-9703-b2270d09c151 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d0b9242f-3a5e-45b4-b9ce-6b94acb1ef85\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_actor')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d0b9242f-3a5e-45b4-b9ce-6b94acb1ef85 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_actor');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            primaryName  birthYear  deathYear  \\\n",
              "0          Fred Astaire       1899     1987.0   \n",
              "1         Lauren Bacall       1924     2014.0   \n",
              "2       Brigitte Bardot       1934        NaN   \n",
              "3          John Belushi       1949     1982.0   \n",
              "4        Ingmar Bergman       1918     2007.0   \n",
              "...                 ...        ...        ...   \n",
              "546416     William Riva       1919     1999.0   \n",
              "546417   Frank J. Gaily       1915     2008.0   \n",
              "546418    Ben Ray Lujan       1972        NaN   \n",
              "546419    Henry Lawfull       2006        NaN   \n",
              "546420      Apsara Rani       1996        NaN   \n",
              "\n",
              "                         primaryProfession           knownForTitle  \n",
              "0             actor,miscellaneous,producer    The Towering Inferno  \n",
              "1       actress,soundtrack,archive_footage    To Have and Have Not  \n",
              "2        actress,music_department,producer                Contempt  \n",
              "3            actor,writer,music_department     Saturday Night Live  \n",
              "4                    writer,director,actor       Wild Strawberries  \n",
              "...                                    ...                     ...  \n",
              "546416                       set_decorator  The Paul Winchell Show  \n",
              "546417                    sound_department             After Hours  \n",
              "546418                     archive_footage            CNN Newsroom  \n",
              "546419                               actor  A Boy Called Christmas  \n",
              "546420                             actress               Dangerous  \n",
              "\n",
              "[546421 rows x 5 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_actor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5-xiVb9UBcv"
      },
      "source": [
        "##  Extracting Data from movie database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEgPQMFPc2Yl"
      },
      "outputs": [],
      "source": [
        "# Parse JSON-like columns (genres, production_companies, etc.)\n",
        "import ast\n",
        "def parse_column(data):\n",
        "    try:\n",
        "        return [item['name'] for item in ast.literal_eval(data)]\n",
        "    except:\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38Zfp66FgW8y"
      },
      "outputs": [],
      "source": [
        "movies['genres'] = movies['genres'].apply(parse_column)\n",
        "movies['production_companies'] = movies['production_companies'].apply(parse_column)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "cmDhGncPgjWf",
        "outputId": "9a037702-a156-47cb-f18d-f10102a0aafb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>production_companies</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Pixar Animation Studios]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[TriStar Pictures, Teitler Film, Interscope Co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Warner Bros., Lancaster Gate]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Twentieth Century Fox Film Corporation]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Sandollar Productions, Touchstone Pictures]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45461</th>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45462</th>\n",
              "      <td>[Sine Olivia]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45463</th>\n",
              "      <td>[American World Pictures]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45464</th>\n",
              "      <td>[Yermoliev]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45465</th>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>45466 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0                                [Pixar Animation Studios]\n",
              "1        [TriStar Pictures, Teitler Film, Interscope Co...\n",
              "2                           [Warner Bros., Lancaster Gate]\n",
              "3                 [Twentieth Century Fox Film Corporation]\n",
              "4             [Sandollar Productions, Touchstone Pictures]\n",
              "                               ...                        \n",
              "45461                                                   []\n",
              "45462                                        [Sine Olivia]\n",
              "45463                            [American World Pictures]\n",
              "45464                                          [Yermoliev]\n",
              "45465                                                   []\n",
              "Name: production_companies, Length: 45466, dtype: object"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "movies['production_companies']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSRKXS3rR_Sv"
      },
      "source": [
        "### complete movie data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oraTJjuEGrP"
      },
      "outputs": [],
      "source": [
        "## another movie dataset with million  movie\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"alanvourch/tmdb-movies-daily-updates\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJfRilpzENYT",
        "outputId": "927a8e7d-053c-44ae-d29a-340a6d7d017f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TMDB_all_movies.csv\n"
          ]
        }
      ],
      "source": [
        "!ls {path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d08msATZEbxa"
      },
      "outputs": [],
      "source": [
        "movie_path= f\"{path}/TMDB_all_movies.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kp0UUJ5VEkBZ"
      },
      "outputs": [],
      "source": [
        "movie_df= pd.read_csv(movie_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7n2DCfrRP3m"
      },
      "outputs": [],
      "source": [
        "# # Load the original dataset\n",
        "# movie_df = pd.read_csv(movie_path)\n",
        "\n",
        "# # Subset the first 45,000 rows using .iloc\n",
        "# subset_df = movie_df.iloc[:44990]\n",
        "\n",
        "# # Save the subset to a new CSV file\n",
        "# subset_df.to_csv(\"subset_movie_data.csv\", index=False, encoding='utf-8')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGQSPaSxUNq9"
      },
      "outputs": [],
      "source": [
        "# with open('subset_movie_data.csv', 'r') as f:\n",
        "#     for i in range(10):  # Print the first 10 lines\n",
        "#         print(f.readline())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMrpZRypJvVl"
      },
      "source": [
        "### IMdb databse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nebXrxrBJu9X",
        "outputId": "08ee742e-d67d-4553-a7a8-8091c6c6241d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/yusufdelikkaya/imdb-movie-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 134k/134k [00:00<00:00, 37.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/yusufdelikkaya/imdb-movie-dataset/versions/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"yusufdelikkaya/imdb-movie-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsP0dNaoKCEH",
        "outputId": "61526560-d4f9-4c4f-9134-6c547213ae1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imdb_movie_dataset.csv\n"
          ]
        }
      ],
      "source": [
        "!ls {path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBpZWL9iJ19p"
      },
      "outputs": [],
      "source": [
        "dat_path= f\"{path}/imdb_movie_dataset.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23de3H7AJ7Vn",
        "outputId": "564df5af-9dd1-438d-cd91-c07c8c6be705",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 12 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   Rank                1000 non-null   int64  \n",
            " 1   Title               1000 non-null   object \n",
            " 2   Genre               1000 non-null   object \n",
            " 3   Description         1000 non-null   object \n",
            " 4   Director            1000 non-null   object \n",
            " 5   Actors              1000 non-null   object \n",
            " 6   Year                1000 non-null   int64  \n",
            " 7   Runtime (Minutes)   1000 non-null   int64  \n",
            " 8   Rating              1000 non-null   float64\n",
            " 9   Votes               1000 non-null   int64  \n",
            " 10  Revenue (Millions)  872 non-null    float64\n",
            " 11  Metascore           936 non-null    float64\n",
            "dtypes: float64(3), int64(4), object(5)\n",
            "memory usage: 93.9+ KB\n"
          ]
        }
      ],
      "source": [
        "#df_imdb= pd.read_csv(dat_path)\n",
        "df_imdb.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UJgNzLOOnSP"
      },
      "source": [
        "### IMdb data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgpDxp9qOrQB"
      },
      "outputs": [],
      "source": [
        "def parse_actors(actor_data):\n",
        "    if isinstance(actor_data, str):\n",
        "        return actor_data.split(\", \")  # Split actors by \", \"\n",
        "    return []\n",
        "\n",
        "df_imdb['parsed_actors'] = df_imdb['Actors'].apply(parse_actors)\n",
        "\n",
        "# Create actor_df with movie_id and individual actor names\n",
        "actor_data = []\n",
        "for _, row in df_imdb.iterrows():\n",
        "    for actor in row['parsed_actors']:\n",
        "        actor_data.append({'movie_id': row['Rank'], 'actor_name': actor})\n",
        "\n",
        "actor_df = pd.DataFrame(actor_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_imdb.head(10)"
      ],
      "metadata": {
        "id": "V-0xqitYW-U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yECLtEVO5C-"
      },
      "outputs": [],
      "source": [
        "actor_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdWekA47PA1y"
      },
      "outputs": [],
      "source": [
        "# parse director\n",
        "director_data = []\n",
        "for _, row in df_imdb.iterrows():\n",
        "    director_data.append({'movie_id': row['Rank'], 'director_name': row['Director']})\n",
        "\n",
        "director_df = pd.DataFrame(director_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nc0BXxedPOWQ"
      },
      "outputs": [],
      "source": [
        "director_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxil0rfMPRRu"
      },
      "outputs": [],
      "source": [
        "def parse_genres(genre_data):\n",
        "    if isinstance(genre_data, str):\n",
        "        return genre_data.split(\",\")  # Split genres by \", \"\n",
        "    return []\n",
        "\n",
        "df_imdb['parsed_genres'] = df_imdb['Genre'].apply(parse_genres)\n",
        "\n",
        "# Create genre_df with movie_id and individual genre names\n",
        "genre_data = []\n",
        "for _, row in df_imdb.iterrows():\n",
        "    for genre in row['parsed_genres']:\n",
        "        genre_data.append({'movie_id': row['Rank'], 'genre_name': genre})\n",
        "\n",
        "genre_df = pd.DataFrame(genre_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XV0O72zfPZFz",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "genre_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QtnuEaxRqqT",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df_imdb.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U31klmWwQ_RH"
      },
      "outputs": [],
      "source": [
        "movie_df = df_imdb.drop(columns=['Actors', 'Director', 'Genre', 'parsed_actors', 'parsed_genres'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS4oQa9KSSlJ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "movie_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y32_dzEiROdA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0Kq7UCdSaCN"
      },
      "source": [
        "### Writing IMdb data to neo4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AgqOO6YUyI6"
      },
      "outputs": [],
      "source": [
        "!pip install neo4j --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6FjQuBJS526"
      },
      "outputs": [],
      "source": [
        "from logging import error\n",
        "import pandas as pd\n",
        "from neo4j.exceptions import ConstraintError  # Import ConstraintError from neo4j.exceptions\n",
        "\n",
        "for _, row in movie_df.iterrows():\n",
        "    # Modified cypher query to use MERGE on title instead of id\n",
        "    cypher = \"\"\"\n",
        "    MERGE (m:Movie {title: $title})\n",
        "    ON CREATE SET m.id = $id,\n",
        "                    m.description = $description,\n",
        "                    m.year = $year,\n",
        "                    m.runtime = $runtime,\n",
        "                    m.rating = $rating,\n",
        "                    m.votes = $votes,\n",
        "                    m.revenue = $revenue,\n",
        "                    m.metascore = $metascore\n",
        "    ON MATCH SET m.description = $description,\n",
        "                    m.year = $year,\n",
        "                    m.runtime = $runtime,\n",
        "                    m.rating = $rating,\n",
        "                    m.votes = $votes,\n",
        "                    m.revenue = $revenue,\n",
        "                    m.metascore = $metascore\n",
        "    \"\"\"\n",
        "    parameters = {\n",
        "        \"id\": row[\"Rank\"],\n",
        "        \"title\": row[\"Title\"],\n",
        "        \"description\": row[\"Description\"],\n",
        "        \"year\": row[\"Year\"],\n",
        "        \"runtime\": row[\"Runtime (Minutes)\"],\n",
        "        \"rating\": row[\"Rating\"],\n",
        "        \"votes\": row[\"Votes\"],\n",
        "        \"revenue\": row[\"Revenue (Millions)\"],\n",
        "        \"metascore\": row[\"Metascore\"]\n",
        "    }\n",
        "\n",
        "    # Try to create/update the node, catching ConstraintError\n",
        "    try:\n",
        "        kg.query(cypher, parameters)\n",
        "    except ConstraintError as e:\n",
        "        # If ConstraintError, print the error message and the conflicting movie title\n",
        "        print(f\"ConstraintError: {e}\")\n",
        "        print(f\"Conflicting movie title: {row['title']}\")\n",
        "        # You can choose to skip the current movie, log it, or handle it differently\n",
        "        # For example, to skip:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU1yeylwX6hB"
      },
      "source": [
        "### relationship among movie , director , genre in neo4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5rQZfPeX56S"
      },
      "outputs": [],
      "source": [
        "#Create Actor Nodes and ACTED_IN Relationships\n",
        "for _, row in actor_df.iterrows():\n",
        "    # Create Actor node\n",
        "    actor_cypher = \"\"\"\n",
        "    MERGE (a:Actor {name: $actor_name})\n",
        "    \"\"\"\n",
        "    kg.query(actor_cypher, {\"actor_name\": row[\"actor_name\"]})\n",
        "\n",
        "    # Create ACTED_IN relationship\n",
        "    relationship_cypher = \"\"\"\n",
        "    MATCH (a:Actor {name: $actor_name}), (m:Movie {id: $movie_id})\n",
        "    MERGE (a)-[:ACTED_IN]->(m)\n",
        "    \"\"\"\n",
        "    kg.query(relationship_cypher, {\"actor_name\": row[\"actor_name\"], \"movie_id\": row[\"movie_id\"]})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qkk6dYhwYdeE"
      },
      "outputs": [],
      "source": [
        "# Create Director Nodes and DIRECTED Relationships\n",
        "for _, row in director_df.iterrows():\n",
        "    # Create Director node\n",
        "    director_cypher = \"\"\"\n",
        "    MERGE (d:Director {name: $director_name})\n",
        "    \"\"\"\n",
        "    kg.query(director_cypher, {\"director_name\": row[\"director_name\"]})\n",
        "\n",
        "    # Create DIRECTED relationship\n",
        "    relationship_cypher = \"\"\"\n",
        "    MATCH (d:Director {name: $director_name}), (m:Movie {id: $movie_id})\n",
        "    MERGE (d)-[:DIRECTED]->(m)\n",
        "    \"\"\"\n",
        "    kg.query(relationship_cypher, {\"director_name\": row[\"director_name\"], \"movie_id\": row[\"movie_id\"]})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1LQMCuLeFlL"
      },
      "outputs": [],
      "source": [
        "#writing genre relatioship with database\n",
        "for _, row in genre_df.iterrows():\n",
        "    # Create Genre node\n",
        "    genre_cypher = \"\"\"\n",
        "    MERGE (g:Genre {name: $genre_name})\n",
        "    \"\"\"\n",
        "    kg.query(genre_cypher, {\"genre_name\": row[\"genre_name\"]})\n",
        "\n",
        "    # Create HAS_GENRE relationship\n",
        "    relationship_cypher = \"\"\"\n",
        "    MATCH (g:Genre {name: $genre_name}), (m:Movie {id: $movie_id})\n",
        "    MERGE (m)-[:HAS_GENRE]->(g)\n",
        "    \"\"\"\n",
        "    kg.query(relationship_cypher, {\"genre_name\": row[\"genre_name\"], \"movie_id\": row[\"movie_id\"]})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4NjHRRBSrsN"
      },
      "source": [
        "## data preprocessin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y4UOwX8SrCI"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import ast\n",
        "\n",
        "# # Load the full dataset\n",
        "# #movie_df = pd.read_csv(movie_path, encoding='utf-8', on_bad_lines='skip')\n",
        "\n",
        "# # Handle missing values\n",
        "# movie_dat.fillna(\"Unknown\", inplace=True)\n",
        "\n",
        "# # Parse JSON-like columns (if necessary)\n",
        "# def parse_column(data):\n",
        "#     if isinstance(data, str):  # Ensure the value is a string\n",
        "#         try:\n",
        "#             # Safely evaluate JSON-like strings\n",
        "#             return [item['name'] for item in ast.literal_eval(data)]\n",
        "#         except (ValueError, SyntaxError, KeyError, TypeError):\n",
        "#             # Return empty list if parsing fails\n",
        "#             return []\n",
        "#     return []  # Return empty list for non-string values\n",
        "\n",
        "\n",
        "# movie_dat['genres'] = movie_dat['genres'].apply(parse_column)\n",
        "# movie_dat['production_companies'] = movie_dat['production_companies'].apply(parse_column)\n",
        "# movie_dat['cast'] = movie_dat['cast'].apply(lambda x: parse_column(x)[:10])  # Limit to top 10 actors\n",
        "\n",
        "# # Validate the processed data\n",
        "# print(movie_dat.head())\n",
        "\n",
        "\n",
        "# movie_dat.to_csv('processed_movie_data.csv', index=False, encoding='utf-8')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0QrFexyFogT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpmcSIqdXpVp"
      },
      "outputs": [],
      "source": [
        "# Drop the 'poster_path' column\n",
        "movie_dat = movie_df.drop('poster_path', axis='columns')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vIUME9gG7Jg"
      },
      "outputs": [],
      "source": [
        "movie_dat.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRnowCwmFr1i"
      },
      "outputs": [],
      "source": [
        "#preprocession\n",
        "'''\n",
        "movie_dat has cat and doirector cloum and thes column has list of vlaues.\n",
        "various actors and directors in onr column.\n",
        "we need to process this to make one idem per row\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Parse the cast column into lists\n",
        "def parse_cast(cast_data):\n",
        "    if isinstance(cast_data, str):\n",
        "        return cast_data.split(\", \")  # Split comma-separated actors\n",
        "    return []\n",
        "\n",
        "# Apply the parsing function\n",
        "movie_dat['parsed_cast'] = movie_dat['cast'].apply(parse_cast)\n",
        "\n",
        "# Create actor_df with movie_id and individual actor names\n",
        "actor_data = []\n",
        "for _, row in movie_dat.iterrows():\n",
        "    for actor in row['parsed_cast']:\n",
        "        if actor.lower() != \"unknown\":  # Exclude 'unknown' values\n",
        "            actor_data.append({'movie_id': row['id'], 'actor_name': actor})\n",
        "\n",
        "actor_df = pd.DataFrame(actor_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSW1paLVGmwE"
      },
      "outputs": [],
      "source": [
        "actor_df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a448_ozYN3C"
      },
      "outputs": [],
      "source": [
        "#movie_dat['cast']\n",
        "# Subset 45,000 rows for Neo4j\n",
        "subset_df = movie_dat.iloc[:45995].copy()\n",
        "\n",
        "# Save the subset as a new CSV file\n",
        "subset_df.to_csv('movie_data_set.csv', index=False, encoding='utf-8')\n",
        "\n",
        "# Verify the subset\n",
        "print(subset_df.head())\n",
        "print(f\"Subset size: {subset_df.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVgQFv2wa9B9"
      },
      "outputs": [],
      "source": [
        "from logging import error\n",
        "import pandas as pd\n",
        "# Use 'on_bad_lines' instead of 'error_bad_lines'\n",
        "# Try using 'engine='python'' for more robust parsing\n",
        "sub = pd.read_csv('movie_data_set.csv', on_bad_lines='skip', sep=',', engine='python')\n",
        "#The on_bad_lines argument can be set to 'skip' to skip bad lines,\n",
        "#'warn' to issue a warning and continue, or 'error' to raise an error.\n",
        "# Using engine='python' can be slower but might handle inconsistencies better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "F1JtJsf_n51O",
        "outputId": "e6359db3-47e7-4b7c-d8b8-50bcae921fe3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[]'"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub['cast'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6ID47zLCHLh"
      },
      "outputs": [],
      "source": [
        "sub.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNpbWkRNgAw3"
      },
      "outputs": [],
      "source": [
        "subset_df = movie_df.iloc[:45995].copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgaLNJZ5bXkl"
      },
      "source": [
        "## Writing movie data to neo4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xitQeVAnbbP7"
      },
      "outputs": [],
      "source": [
        "from logging import error\n",
        "import pandas as pd\n",
        "from neo4j import ConstraintError  # Import ConstraintError from neo4j\n",
        "\n",
        "# Use 'on_bad_lines' instead of 'error_bad_lines'\n",
        "# Try using 'engine='python'' for more robust parsing\n",
        "sub = pd.read_csv('movie_data_set.csv', on_bad_lines='skip', sep=',', engine='python')\n",
        "#The on_bad_lines argument can be set to 'skip' to skip bad lines,\n",
        "#'warn' to issue a warning and continue, or 'error' to raise an error.\n",
        "# Using engine='python' can be slower but might handle inconsistencies better\n",
        "\n",
        "\n",
        "\n",
        "for _, row in subset_df.iterrows():\n",
        "    cypher = \"\"\"\n",
        "    MERGE (m:Movie {id: $id})\n",
        "    ON CREATE SET m.title = $title,\n",
        "                  m.release_date = $release_date,\n",
        "                  m.vote_average = $vote_average,\n",
        "                  m.vote_count = $vote_count,\n",
        "                  m.revenue = $revenue,\n",
        "                  m.budget = $budget,\n",
        "                  m.runtime = $runtime\n",
        "    ON MATCH SET m.release_date = COALESCE(m.release_date, $release_date),\n",
        "                 m.vote_average = COALESCE(m.vote_average, $vote_average),\n",
        "                 m.vote_count = COALESCE(m.vote_count, $vote_count),\n",
        "                 m.revenue = COALESCE(m.revenue, $revenue),\n",
        "                 m.budget = COALESCE(m.budget, $budget),\n",
        "                 m.runtime = COALESCE(m.runtime, $runtime);\n",
        "    \"\"\"\n",
        "\n",
        "    parameters = {\n",
        "        \"id\": row[\"id\"],\n",
        "        \"title\": row[\"title\"],\n",
        "        \"release_date\": row[\"release_date\"],\n",
        "        \"vote_average\": row[\"vote_average\"],\n",
        "        \"vote_count\": row[\"vote_count\"],\n",
        "        \"revenue\": row[\"revenue\"],\n",
        "        \"budget\": row[\"budget\"],\n",
        "        \"runtime\": row[\"runtime\"]\n",
        "    }\n",
        "\n",
        "    # Try to create/update the node, catching ConstraintError\n",
        "    try:\n",
        "        kg.query(cypher, parameters)\n",
        "    except ConstraintError as e:\n",
        "        # If ConstraintError, print the error message and the conflicting movie title\n",
        "        print(f\"ConstraintError: {e}\")\n",
        "        print(f\"Conflicting movie title: {row['title']}\")\n",
        "        # You can choose to skip the current movie, log it, or handle it differently\n",
        "        # For example, to skip:\n",
        "        # continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPPXRAcUrNZi"
      },
      "outputs": [],
      "source": [
        "!pip install neo4j --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEawmyxHrR7_"
      },
      "outputs": [],
      "source": [
        "from logging import error\n",
        "import pandas as pd\n",
        "from neo4j.exceptions import ConstraintError  # Import ConstraintError from neo4j.exceptions\n",
        "\n",
        "# Use 'on_bad_lines' instead of 'error_bad_lines'\n",
        "# Try using 'engine='python'' for more robust parsing\n",
        "sub = pd.read_csv('movie_data_set.csv', on_bad_lines='skip', sep=',', engine='python')\n",
        "#The on_bad_lines argument can be set to 'skip' to skip bad lines,\n",
        "#'warn' to issue a warning and continue, or 'error' to raise an error.\n",
        "# Using engine='python' can be slower but might handle inconsistencies better\n",
        "\n",
        "\n",
        "\n",
        "for _, row in subset_df.iterrows():\n",
        "    cypher = \"\"\"\n",
        "    MERGE (m:Movie {id: $id})\n",
        "    ON CREATE SET m.title = $title,\n",
        "                  m.release_date = $release_date,\n",
        "                  m.vote_average = $vote_average,\n",
        "                  m.vote_count = $vote_count,\n",
        "                  m.revenue = $revenue,\n",
        "                  m.budget = $budget,\n",
        "                  m.runtime = $runtime\n",
        "    ON MATCH SET m.release_date = COALESCE(m.release_date, $release_date),\n",
        "                 m.vote_average = COALESCE(m.vote_average, $vote_average),\n",
        "                 m.vote_count = COALESCE(m.vote_count, $vote_count),\n",
        "                 m.revenue = COALESCE(m.revenue, $revenue),\n",
        "                 m.budget = COALESCE(m.budget, $budget),\n",
        "                 m.runtime = COALESCE(m.runtime, $runtime);\n",
        "    \"\"\"\n",
        "\n",
        "    parameters = {\n",
        "        \"id\": row[\"id\"],\n",
        "        \"title\": row[\"title\"],\n",
        "        \"release_date\": row[\"release_date\"],\n",
        "        \"vote_average\": row[\"vote_average\"],\n",
        "        \"vote_count\": row[\"vote_count\"],\n",
        "        \"revenue\": row[\"revenue\"],\n",
        "        \"budget\": row[\"budget\"],\n",
        "        \"runtime\": row[\"runtime\"]\n",
        "    }\n",
        "\n",
        "    # Try to create/update the node, catching ConstraintError\n",
        "    try:\n",
        "        kg.query(cypher, parameters)\n",
        "    except ConstraintError as e:\n",
        "        # If ConstraintError, print the error message and the conflicting movie title\n",
        "        print(f\"ConstraintError: {e}\")\n",
        "        print(f\"Conflicting movie title: {row['title']}\")\n",
        "        # You can choose to skip the current movie, log it, or handle it differently\n",
        "        # For example, to skip:\n",
        "        # continue"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding poster and trailer link to the Neo4j database\n",
        "Using OMDB API"
      ],
      "metadata": {
        "id": "gZL_zmsXLyNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sn8sdNU2R5Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "# Get the API key from the environment\n",
        "import os\n",
        "from google.colab import userdata # we stored our access token as a colab secret\n",
        "\n",
        "os.environ[\"OMDBI_API_TOKEN\"] = userdata.get('OMDB_api')\n",
        "api_key = os.environ.get(\"OMDBI_API_TOKEN\")\n",
        "\n",
        "if not api_key:\n",
        "    print(\"API key not found in the environment.\")\n",
        "    exit(1)\n",
        "\n",
        "# Function to fetch data from OMDb\n",
        "def fetch_omdb_data(title, year=None):\n",
        "    url = f\"http://www.omdbapi.com/?t={title}&apikey={api_key}\"\n",
        "    if year:\n",
        "        url += f\"&y={year}\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        if data.get(\"Response\") == \"True\":\n",
        "            return {\n",
        "                \"poster_url\": data.get(\"Poster\"),\n",
        "                \"description\": data.get(\"Plot\")\n",
        "            }\n",
        "        else:\n",
        "            print(f\"OMDb Error: {data.get('Error')} for title: {title}\")\n",
        "    else:\n",
        "        print(f\"HTTP Error: {response.status_code}\")\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "6wR0K-MHLx7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = fetch_omdb_data(\"Guardians of the Galaxy\", year=2014)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyuyR0xgOjEO",
        "outputId": "023d36c9-16f4-4b79-e0f3-9de1444638ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'poster_url': 'https://m.media-amazon.com/images/M/MV5BM2ZmNjQ2MzAtNDlhNi00MmQyLWJhZDMtNmJiMjFlOWY4MzcxXkEyXkFqcGc@._V1_SX300.jpg', 'description': 'A group of intergalactic criminals must pull together to stop a fanatical warrior with plans to purge the universe.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keybert import KeyBERT\n",
        "\n",
        "# Initialize KeyBERT model\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "def extract_keywords(text):\n",
        "    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words=\"english\")\n",
        "    return [kw[0] for kw in keywords]\n",
        "\n",
        "# Example: Use the description to generate keywords\n",
        "movie_data = fetch_omdb_data(\"Guardians of the Galaxy\", year=2014)\n",
        "if movie_data:\n",
        "    keywords = extract_keywords(movie_data[\"description\"])\n",
        "    print(\"Keywords:\", keywords)\n"
      ],
      "metadata": {
        "id": "OJylm_Q-T36x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating tagline and keywords using bert\n",
        "In this section I will pull description paramter form the movie from neo4j then we will create a tagöline and few keywords for a prticular movie. Later , we will write bakc to the database keywords and taglines to neo4j"
      ],
      "metadata": {
        "id": "ykC1bAOlVpPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keybert import KeyBERT\n",
        "\n",
        "# Initialize KeyBERT\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "# Fetch movie descriptions from Neo4j\n",
        "def get_movie_descriptions():\n",
        "    cypher = \"\"\"\n",
        "    MATCH (m:Movie)\n",
        "    RETURN m.id AS id, m.description AS description\n",
        "    \"\"\"\n",
        "    results = kg.query(cypher)\n",
        "    return [{\"id\": record[\"id\"], \"description\": record[\"description\"]} for record in results]\n",
        "\n",
        "# Generate keywords and tagline\n",
        "def generate_keywords_and_tagline(description):\n",
        "    keywords = kw_model.extract_keywords(description, keyphrase_ngram_range=(1, 2), stop_words=\"english\")\n",
        "    keywords = [kw[0] for kw in keywords]\n",
        "    tagline = f\"A story about {keywords[0]}\" if keywords else \"A story worth watching.\"\n",
        "    return keywords, tagline\n",
        "\n",
        "# Process all movie data\n",
        "def process_and_update_movies():\n",
        "    movie_data = get_movie_descriptions()\n",
        "    for movie in movie_data:\n",
        "        if movie[\"description\"]:  # Ensure description is not None\n",
        "            keywords, tagline = generate_keywords_and_tagline(movie[\"description\"])\n",
        "\n",
        "            # Update Neo4j\n",
        "            cypher = \"\"\"\n",
        "            MATCH (m:Movie {id: $id})\n",
        "            SET m.keywords = $keywords, m.tagline = $tagline\n",
        "            \"\"\"\n",
        "            parameters = {\n",
        "                \"id\": movie[\"id\"],\n",
        "                \"keywords\": keywords,\n",
        "                \"tagline\": tagline\n",
        "            }\n",
        "            kg.query(cypher, parameters)\n",
        "\n",
        "# Execute the processing\n",
        "process_and_update_movies()\n"
      ],
      "metadata": {
        "id": "bSzNjZR4WN-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing Tagline and keywords from another database\n"
      ],
      "metadata": {
        "id": "1oX2VqSTAbvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"juzershakir/tmdb-movies-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "f8IoiFl3AydC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls {path}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbrayzThA3iT",
        "outputId": "4bec206a-490e-4f18-f6b0-1e521091678e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tmdb_movies_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag_path = f\"{path}/tmdb_movies_data.csv\"\n",
        "tag_line_df = pd.read_csv(tag_path)  # Use the variable, not the literal string\n",
        "#print(tag_path)\n",
        "\n",
        "tag_line_df.info()"
      ],
      "metadata": {
        "id": "7UG6uOWABVkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "merging both db for getting tagline and kewords"
      ],
      "metadata": {
        "id": "thA90BaUEWE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the two datasets on Title and Year\n",
        "merged_df = pd.merge(\n",
        "    df_imdb,  # Your 1000 movie entries\n",
        "    tag_line_df,  # The DataFrame with taglines and keywords\n",
        "    left_on=[\"Title\", \"Year\"],\n",
        "    right_on=[\"original_title\", \"release_year\"],\n",
        "    how=\"inner\"\n",
        ")\n",
        "\n",
        "# Check the merged DataFrame\n",
        "#print(merged_df[['Title', 'Year', 'tagline', 'keywords']].head())\n",
        "\n",
        "merged_df.info()\n"
      ],
      "metadata": {
        "id": "UDqSRhMAEcgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def fetch_movie_data_from_tmdb(title):\n",
        "    # Search for the movie\n",
        "    search_url = f\"https://api.themoviedb.org/3/search/movie?api_key={TMDB_API_KEY}&query={title}\"\n",
        "    if year:\n",
        "        search_url += f\"&year={year}\"\n",
        "\n",
        "    response = requests.get(search_url)\n",
        "    if response.status_code == 200:\n",
        "        search_results = response.json().get(\"results\", [])\n",
        "        if search_results:\n",
        "            # Fetch the first matching movie's details\n",
        "            movie_id = search_results[0][\"id\"]\n",
        "            movie_details_url = f\"https://api.themoviedb.org/3/movie/{movie_id}?api_key={TMDB_API_KEY}\"\n",
        "            movie_details = requests.get(movie_details_url).json()\n",
        "\n",
        "            # Extract tagline and keywords\n",
        "            tagline = movie_details.get(\"tagline\", \"No tagline available\")\n",
        "\n",
        "            # Keywords are fetched from a different endpoint\n",
        "            keywords_url = f\"https://api.themoviedb.org/3/movie/{movie_id}/keywords?api_key={TMDB_API_KEY}\"\n",
        "            keywords_response = requests.get(keywords_url).json()\n",
        "            keywords = [k[\"name\"] for k in keywords_response.get(\"keywords\", [])]\n",
        "\n",
        "            return tagline, keywords\n",
        "    return None, []\n"
      ],
      "metadata": {
        "id": "szQmiLkTF9hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test above code\n",
        "title = \"\tPrometheus\"\n",
        "year = 2012\n",
        "tagline, keywords = fetch_movie_data_from_tmdb(title)\n",
        "print(f\"Tagline: {tagline}\")\n",
        "print(f\"Keywords: {keywords}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toeD4lc5GH62",
        "outputId": "7d59873c-9545-4f93-bdd5-0249b60001ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tagline: The search for our beginning could lead to our end.\n",
            "Keywords: ['android', 'alien', 'space', 'creature', 'spin off', 'creation', 'emergency surgery', 'stasis', 'archeological dig', 'god complex', 'cave drawing', 'prometheus', 'genetic mutation', 'origins of life', '2090s', 'objective']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "writing tagline and keyowrds to the neo4j DB"
      ],
      "metadata": {
        "id": "10HegBoEG0o8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_movie_in_neo4j(title, tagline, keywords):\n",
        "    query = \"\"\"\n",
        "    MATCH (m:Movie {title: $title})\n",
        "    SET m.tagline = $tagline, m.keywords = $keywords\n",
        "    \"\"\"\n",
        "    with driver.session() as session:\n",
        "        session.run(query, {\"title\": title, \"tagline\": tagline, \"keywords\": keywords})\n",
        "\n",
        "# Assuming `df_imdb` is your DataFrame with the 1000 movies\n",
        "\n",
        "for _, row in df_imdb.iterrows():\n",
        "    title = row['Title']  # Title of the movie\n",
        "    #year = row['Year']    # Release year of the movie\n",
        "\n",
        "    try:\n",
        "        # Fetch data from TMDB\n",
        "        tagline, keywords = fetch_movie_data_from_tmdb(title)\n",
        "\n",
        "        # Update Neo4j\n",
        "        update_movie_in_neo4j(title, tagline, keywords)\n",
        "        print(f\"Updated: {title} with tagline and keywords.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to update {title} \")\n",
        "\n"
      ],
      "metadata": {
        "id": "RwznYWEUG5qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some keywords and taglines are null value there is need to rewrite those . We will use bert function like aboive to rewrite"
      ],
      "metadata": {
        "id": "OTt5Rm52cVhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "replacing Null values in tagline and keywords.\n",
        "Tagliens and Kewords has been wriiten uing TMDB api . But some of them were empty\n",
        ". So we are going to genrate empyty tagline and keywords using bert\n",
        "from description parameter\n",
        "\"\"\"\n",
        "def update_tagline_and_key_movies():\n",
        "    movie_data = get_movie_descriptions()  # Fetch movies from Neo4j\n",
        "    for movie in movie_data:\n",
        "        if movie[\"description\"]:  # Ensure the description is valid\n",
        "            keywords, tagline = generate_keywords_and_tagline(movie[\"description\"])\n",
        "\n",
        "            # Update only null fields in Neo4j\n",
        "            cypher = \"\"\"\n",
        "            MATCH (m:Movie {id: $id})\n",
        "            SET\n",
        "                m.tagline = CASE\n",
        "                               WHEN m.tagline IS NULL OR m.tagline = \"\" THEN $tagline\n",
        "                               ELSE m.tagline\n",
        "                           END,\n",
        "                m.keywords = CASE\n",
        "                               WHEN m.keywords IS NULL OR m.keywords = \"\" THEN $keywords\n",
        "                               ELSE m.keywords\n",
        "                           END\n",
        "            \"\"\"\n",
        "            parameters = {\n",
        "                \"id\": movie[\"id\"],\n",
        "                \"keywords\": keywords,\n",
        "                \"tagline\": tagline\n",
        "            }\n",
        "            try:\n",
        "                kg.query(cypher, parameters)\n",
        "                print(f\"Updated movie {movie['id']} with tagline and keywords.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to update movie {movie['id']}: {e}\")\n"
      ],
      "metadata": {
        "id": "q0vXXHuscfjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "update_tagline_and_key_movies()"
      ],
      "metadata": {
        "id": "50w4xWBCd03K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_keywords():\n",
        "    movie_data = get_movie_descriptions()  # Fetch movies from Neo4j\n",
        "    for movie in movie_data:\n",
        "        if movie[\"description\"]:  # Ensure the description is valid\n",
        "            keywords, tagline = generate_keywords_and_tagline(movie[\"description\"])\n",
        "            cypher = \"\"\"\n",
        "            MATCH (m:Movie {id: $id})\n",
        "            SET\n",
        "                m.keywords = CASE\n",
        "                               WHEN m.keywords IS NULL OR m.keywords = [] THEN $keywords\n",
        "                               ELSE m.keywords\n",
        "                           END\n",
        "            \"\"\"\n",
        "            parameters = {\n",
        "                \"id\": movie[\"id\"],\n",
        "                \"keywords\": keywords\n",
        "            }\n",
        "            try:\n",
        "                kg.query(cypher, parameters)\n",
        "                print(f\"Updated movie {movie['id']} with keywords.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to update movie {movie['id']}: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "qIsXvb3emrCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "update_keywords()"
      ],
      "metadata": {
        "id": "HU7PlJoOncJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing query\n",
        "cypher = \"\"\"\n",
        "MATCH (m:Movie)\n",
        "WHERE $keyword IN m.keywords\n",
        "RETURN m.title, m.tagline, m.description\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "kg.query(cypher, {\"keyword\": \"war\"})\n"
      ],
      "metadata": {
        "id": "T1vkhM9ujCXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Text for RAG\n",
        "In this section we will create text embedding for rag . We will use tagline for embedding for implementaing better RAG system"
      ],
      "metadata": {
        "id": "Yv1lckthavba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### creating vector index"
      ],
      "metadata": {
        "id": "SkXTcN3IeMuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"\"\"\n",
        "  CREATE VECTOR INDEX movie_tagline_embeddings IF NOT EXISTS\n",
        "  FOR (m:Movie) ON (m.taglineEmbedding)\n",
        "  OPTIONS { indexConfig: {\n",
        "    `vector.dimensions`: 1536,\n",
        "    `vector.similarity_function`: 'cosine'\n",
        "  }}\"\"\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpZHxoB7bq83",
        "outputId": "1f897b53-22c5-4a26-d281-00c79db89740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"\"\"\n",
        "  SHOW VECTOR INDEXES\n",
        "  \"\"\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UvuD3L9cDn9",
        "outputId": "af788ed8-f3c6-4df1-a5d9-9bc45c986ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 6,\n",
              "  'name': 'movie_tagline_embeddings',\n",
              "  'state': 'ONLINE',\n",
              "  'populationPercent': 100.0,\n",
              "  'type': 'VECTOR',\n",
              "  'entityType': 'NODE',\n",
              "  'labelsOrTypes': ['Movie'],\n",
              "  'properties': ['taglineEmbedding'],\n",
              "  'indexProvider': 'vector-2.0',\n",
              "  'owningConstraint': None,\n",
              "  'lastRead': None,\n",
              "  'readCount': 0}]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Populate the vector Index"
      ],
      "metadata": {
        "id": "PNZxjYazeTuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Invoking hugging face for emnbedding models"
      ],
      "metadata": {
        "id": "iNGsaQmAkROx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata # we stored our access token as a colab secret\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('new_token')"
      ],
      "metadata": {
        "id": "rNrzPFwfkOLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install -qqq -U langchain-huggingface\n",
        "pip install -qqq -U langchain\n",
        "pip install -qqq -U langchain-community\n",
        "pip install -qqq -U faiss-cpu\n",
        "pip install -qU langchain_community\n",
        "pip install -qU pymupdf"
      ],
      "metadata": {
        "id": "6jSUDpMkkwtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Setting up LLM\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "# This info's at the top of each HuggingFace model page\n",
        "hf_model = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "\n",
        "llm = HuggingFaceEndpoint(repo_id = hf_model)"
      ],
      "metadata": {
        "id": "qwF00drDkhI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## embedding model\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# embeddings\n",
        "embedding_model = \"sentence-transformers/all-MiniLM-l6-v2\"\n",
        "embeddings_folder = \"/content/\"\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=embedding_model,\n",
        "                                   cache_folder=embeddings_folder)"
      ],
      "metadata": {
        "id": "tl27KFZjmP0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#uding huggingface model for creating embedding\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "kg.query(\"\"\"\n",
        "  MATCH (m:Movie)\n",
        "  WHERE m.tagline IS NOT NULL\n",
        "  WITH m, HuggingFaceEmbeddings(embedding_model) AS embedder\n",
        "  SET m.taglineEmbedding = embedder.embed_query(m.tagline)\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "SjWW9E_TmvB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing HuggingFace model for embedding"
      ],
      "metadata": {
        "id": "XisRH_vZoJzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "def fetch_movies_with_taglines():\n",
        "    cypher = \"\"\"\n",
        "    MATCH (m:Movie) WHERE m.tagline IS NOT NULL\n",
        "    RETURN m.id AS id, m.tagline AS tagline\n",
        "    \"\"\"\n",
        "    results = kg.query(cypher)\n",
        "    return [{\"id\": record[\"id\"], \"tagline\": record[\"tagline\"]} for record in results]\n",
        "def generate_embedding(tagline):\n",
        "    return embedding_model.encode(tagline).tolist()\n",
        "\n",
        "def update_movie_embedding(movie_id, embedding):\n",
        "    cypher = \"\"\"\n",
        "    MATCH (m:Movie {id: $id})\n",
        "    SET m.taglineEmbedding = $embedding\n",
        "    \"\"\"\n",
        "    with driver.session() as session:\n",
        "        session.run(cypher, {\"id\": movie_id, \"embedding\": embedding})\n",
        "\n",
        "def process_and_update_embeddings():\n",
        "    movies = fetch_movies_with_taglines()\n",
        "    for movie in movies:\n",
        "        tagline = movie[\"tagline\"]\n",
        "        movie_id = movie[\"id\"]\n",
        "\n",
        "        # Generate embedding\n",
        "        embedding = generate_embedding(tagline)\n",
        "\n",
        "        # Update Neo4j\n",
        "        update_movie_embedding(movie_id, embedding)\n",
        "        print(f\"Updated movie ID {movie_id} with tagline embedding.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P7ZRZI7ZoRdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the processing\n",
        "process_and_update_embeddings()"
      ],
      "metadata": {
        "id": "mdPbNsVAo7E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Query the embeddings from neo4j\n",
        "I am using neo4j AuraDB free version of knowledge graph database. Vectir databse is not avaialbel for this. So i used emebeiddng vecotr as list and retriveing cosine similarity suong manully . it is giving recemmendatiuon manually."
      ],
      "metadata": {
        "id": "ERebdoGFqsmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_movie_embeddings():\n",
        "    cypher = \"\"\"\n",
        "    MATCH (m:Movie)\n",
        "    WHERE m.taglineEmbedding IS NOT NULL\n",
        "    RETURN m.id AS id, m.title AS title, m.taglineEmbedding AS embedding\n",
        "    \"\"\"\n",
        "    results = kg.query(cypher)\n",
        "    return [{\"id\": record[\"id\"], \"title\": record[\"title\"], \"embedding\": record[\"embedding\"]} for record in results]"
      ],
      "metadata": {
        "id": "F_u5y5zXqyCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "\n",
        "# Cosine similarity\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
        "\n",
        "# Example function to recommend movies\n",
        "def recommend_movies(query, top_k=5):\n",
        "    # Generate embedding for the query using Hugging Face\n",
        "    query_embedding = embedding_model.encode(query).tolist()\n",
        "\n",
        "    # Fetch movie embeddings from Neo4j\n",
        "    movies = fetch_movie_embeddings()\n",
        "\n",
        "    # Calculate similarity scores\n",
        "    similarities = [\n",
        "        {\"id\": movie[\"id\"], \"title\": movie[\"title\"], \"score\": cosine_similarity(query_embedding, movie[\"embedding\"])}\n",
        "        for movie in movies\n",
        "    ]\n",
        "\n",
        "    # Sort by similarity score and return top_k results\n",
        "    recommendations = sorted(similarities, key=lambda x: x[\"score\"], reverse=True)[:top_k]\n",
        "    return recommendations\n"
      ],
      "metadata": {
        "id": "c2RVkeMS3dD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "question = \"A Love story.\"\n",
        "recommendations = recommend_movies(question)\n",
        "\n",
        "print(\"Top Recommendations:\")\n",
        "for rec in recommendations:\n",
        "    print(f\"Title: {rec['title']}, Similarity Score: {rec['score']}\")\n"
      ],
      "metadata": {
        "id": "FAZG4N053imS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improve Query with LLM , Prompt Engineering.\n",
        "Simple query will give answer to one type of question at one time we can levereage llm and other models to dveelop a robust rag. that can answer seevral qestion at one time . With the help of porompt engineering. for example . What is highly rated mobvie give moive like them . what is movie between 2006 to 2008 , can you receomend movie like adventure"
      ],
      "metadata": {
        "id": "wr8Y9RE7Vaqg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Writing Cypher with LLM"
      ],
      "metadata": {
        "id": "R5qmvCiiWWgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "import textwrap\n",
        "\n",
        "# Langchain\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "from langchain.chains import GraphCypherQAChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "LDz64IPyVleu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CYPHER_GENERATION_TEMPLATE = \"\"\"Task:Generate Cypher statement to\n",
        "query a graph database.\n",
        "Instructions:\n",
        "Use only the provided relationship types and properties in the\n",
        "schema. Do not use any other relationship types or properties that\n",
        "are not provided.\n",
        "Schema:\n",
        "{schema}\n",
        "Note: Do not include any explanations or apologies in your responses.\n",
        "Do not respond to any questions that might ask anything else than\n",
        "for you to construct a Cypher statement.\n",
        "Do not include any text except the generated Cypher statement.\n",
        "Examples: Here are a few examples of generated Cypher\n",
        "statements for particular questions:\n",
        "\n",
        "# What are movies after year 2006?\n",
        "Match (m:Movie)\n",
        "where m.year > 2006\n",
        "Return m.year, m.title\n",
        "kg.query(cypher)\n",
        "The question is:\n",
        "{question}\"\"\"\n"
      ],
      "metadata": {
        "id": "-xa5gV7NRZ1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"schema\", \"question\"],\n",
        "    template=CYPHER_GENERATION_TEMPLATE\n",
        ")"
      ],
      "metadata": {
        "id": "PG47nRe8Re6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cypherChain = GraphCypherQAChain.from_llm(\n",
        "    ChatOpenAI(temperature=0),\n",
        "    graph=kg,\n",
        "    verbose=True,\n",
        "    cypher_prompt=CYPHER_GENERATION_PROMPT,\n",
        "    allow_dangerous_requests=True\n",
        ")"
      ],
      "metadata": {
        "id": "f5aVcWvPRmIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prettyCypherChain(question: str) -> str:\n",
        "    response = cypherChain.run(question)\n",
        "    print(textwrap.fill(response, 60))"
      ],
      "metadata": {
        "id": "AMGeg5QwRqPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prettyCypherChain(\"What are movies after 2007?\")"
      ],
      "metadata": {
        "id": "uR-UZbs2UWj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Streamlit with cypher generation with llm\n",
        "Another method of query"
      ],
      "metadata": {
        "id": "0bmZ0AZvKpl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "\n",
        "CYPHER_GENERATION_TEMPLATE = \"\"\"Task:Generate Cypher statement to query a graph database.\n",
        "Instructions:\n",
        "Use only the provided relationship types and properties in the schema.\n",
        "Do not use any other relationship types or properties that are not provided.\n",
        "Schema:\n",
        "{schema}\n",
        "Note: Do not include any explanations or apologies in your responses.\n",
        "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
        "Do not include any text except the generated Cypher statement.\n",
        "Examples: Here are a few examples of generated Cypher statements for particular questions:\n",
        "\n",
        "# How many people played in Top Gun?\n",
        "MATCH (m:Movie {{name:\"Top Gun\"}})<-[:ACTED_IN]-()\n",
        "RETURN count(*) AS numberOfActors\n",
        "\n",
        "# What are movies after year 2006?\n",
        "Match (m:Movie)\n",
        "where m.year > 2006\n",
        "Return m.year, m.title\n",
        "The question is:\n",
        "{question}\"\"\"\n",
        "\n",
        "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"schema\", \"question\"], template=CYPHER_GENERATION_TEMPLATE\n",
        ")\n",
        "\n",
        "chain = GraphCypherQAChain.from_llm(\n",
        "    graph=kg,\n",
        "    cypher_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\"),\n",
        "    qa_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-16k\"),\n",
        "    verbose=True,\n",
        "    allow_dangerous_requests=True,\n",
        ")"
      ],
      "metadata": {
        "id": "RkOygNvwIbo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"query\": \"movie A love story\"})\n",
        "#chain.invoke({\"query\":\"What are movies after 2008\"})\n",
        "\n"
      ],
      "metadata": {
        "id": "fpeL-vWIph-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### check effect of preprocessing query"
      ],
      "metadata": {
        "id": "SSNOAa1Q6sJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import re\n",
        "# def preprocess_query(query):\n",
        "#     # Define a list of stopwords to remove\n",
        "#     stopwords = [\"recommend\", \"movie\", \"similar\", \"movies\", \"show\", \"find\", \"me\", \"please\"]\n",
        "\n",
        "#     # Lowercase the query for consistency\n",
        "#     query = query.lower()\n",
        "\n",
        "#     # Remove stopwords\n",
        "#     for word in stopwords:\n",
        "#         query = query.replace(word, \"\")\n",
        "\n",
        "#     # Remove single characters\n",
        "#     query = re.sub(r'\\b\\w\\b', '', query)\n",
        "\n",
        "#     # Remove extra spaces\n",
        "#     query = re.sub(r'\\s+', ' ', query).strip()\n",
        "\n",
        "#     # Remove punctuation\n",
        "#     query = re.sub(r'[^\\w\\s]', '', query)\n",
        "\n",
        "#     return query\n",
        "def preprocess_query(query):\n",
        "    stopwords = [\"recommend\", \"movie\", \"similar\", \"movies\", \"show\", \"find\", \"me\", \"please\"]\n",
        "    query = query.lower()\n",
        "    # Remove only stopwords, not structural terms\n",
        "    query_words = query.split()\n",
        "    filtered_words = [word for word in query_words if word not in stopwords]\n",
        "    return \" \".join(filtered_words)\n"
      ],
      "metadata": {
        "id": "j4zdU1XcxcIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocess_query(\"Recommend movies like Interstellar\"))\n",
        "# Output: \"like interstellar\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne8xvHxrAy1O",
        "outputId": "09fd8811-0169-4917-bcfa-5bd657aa3e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "like interstellar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NZMmzUydA4Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def recommend_movies(query, top_k=5):\n",
        "#     # Step 1: Preprocess query\n",
        "#     processed_query = preprocess_query(query)\n",
        "#     print(f\"Processed Query: {processed_query}\")\n",
        "\n",
        "#     # Step 2: Check if query is \"movies like [X]\"\n",
        "#     if \"like\" in processed_query:\n",
        "#         # Extract target movie\n",
        "#         target_movie = processed_query.split(\"like\")[-1].strip()\n",
        "#         print(f\"Target Movie: {target_movie}\")\n",
        "\n",
        "#         # Fetch target movie embedding\n",
        "#         cypher = f\"\"\"\n",
        "#         MATCH (m:Movie)\n",
        "#         WHERE toLower(m.title) = toLower(\"{target_movie}\")\n",
        "#         RETURN m.id AS id, m.taglineEmbedding AS embedding\n",
        "#         \"\"\"\n",
        "#         print(f\"Cypher Query to Fetch Target Embedding: {cypher}\")\n",
        "\n",
        "#         target_embedding_result = kg.query(cypher)\n",
        "#         if not target_embedding_result:\n",
        "#             return [{\"title\": f\"Movie '{target_movie}' not found\", \"score\": 0.0}]\n",
        "\n",
        "#         target_movie_id = target_embedding_result[0][\"id\"]\n",
        "#         target_embedding = target_embedding_result[0][\"embedding\"]\n",
        "#         print(f\"Target Movie Embedding: {target_embedding}\")\n",
        "\n",
        "#         # Fetch all movie embeddings excluding the target movie\n",
        "#         movies = fetch_movie_embeddings()\n",
        "#         filtered_movies = [movie for movie in movies if movie[\"id\"] != target_movie_id]\n",
        "\n",
        "#         # Calculate similarities\n",
        "#         similarities = [\n",
        "#             {\n",
        "#                 \"id\": movie[\"id\"],\n",
        "#                 \"title\": movie[\"title\"],\n",
        "#                 \"score\": cosine_similarity(target_embedding, movie[\"embedding\"]),\n",
        "#             }\n",
        "#             for movie in filtered_movies\n",
        "#         ]\n",
        "\n",
        "#         # Sort and return top results\n",
        "#         recommendations = sorted(similarities, key=lambda x: x[\"score\"], reverse=True)[:top_k]\n",
        "#         return recommendations\n",
        "#     else:\n",
        "#         # Handle other queries with standard embedding\n",
        "#         query_embedding = embedding_model.encode(processed_query).tolist()\n",
        "#         movies = fetch_movie_embeddings()\n",
        "\n",
        "#         similarities = [\n",
        "#             {\n",
        "#                 \"id\": movie[\"id\"],\n",
        "#                 \"title\": movie[\"title\"],\n",
        "#                 \"score\": cosine_similarity(query_embedding, movie[\"embedding\"]),\n",
        "#             }\n",
        "#             for movie in movies\n",
        "#         ]\n",
        "\n",
        "#         recommendations = sorted(similarities, key=lambda x: x[\"score\"], reverse=True)[:top_k]\n",
        "#         return recommendations\n",
        "def recommend_movies(query, top_k=5):\n",
        "    processed_query = preprocess_query(query)\n",
        "    print(f\"Processed Query: {processed_query}\")\n",
        "\n",
        "    if \"like\" in processed_query:\n",
        "        target_movie = processed_query.split(\"like\")[-1].strip()\n",
        "        print(f\"Target Movie: {target_movie}\")\n",
        "\n",
        "        cypher = f\"\"\"\n",
        "        MATCH (m:Movie)\n",
        "        WHERE toLower(m.title) = toLower(\"{target_movie}\")\n",
        "        RETURN m.id AS id, m.taglineEmbedding AS embedding\n",
        "        \"\"\"\n",
        "        target_embedding_result = kg.query(cypher)\n",
        "\n",
        "        if not target_embedding_result:\n",
        "            return [{\"title\": f\"Movie '{target_movie}' not found\", \"score\": 0.0}]\n",
        "\n",
        "        target_movie_id = target_embedding_result[0][\"id\"]\n",
        "        target_embedding = target_embedding_result[0][\"embedding\"]\n",
        "\n",
        "        movies = fetch_movie_embeddings()\n",
        "        filtered_movies = [movie for movie in movies if movie[\"id\"] != target_movie_id]\n",
        "\n",
        "        similarities = [\n",
        "            {\n",
        "                \"id\": movie[\"id\"],\n",
        "                \"title\": movie[\"title\"],\n",
        "                \"score\": cosine_similarity(target_embedding, movie[\"embedding\"]),\n",
        "            }\n",
        "            for movie in filtered_movies\n",
        "        ]\n",
        "\n",
        "        recommendations = sorted(similarities, key=lambda x: x[\"score\"], reverse=True)[:top_k]\n",
        "        return recommendations\n",
        "    else:\n",
        "        query_embedding = embedding_model.encode(processed_query).tolist()\n",
        "        movies = fetch_movie_embeddings()\n",
        "\n",
        "        similarities = [\n",
        "            {\n",
        "                \"id\": movie[\"id\"],\n",
        "                \"title\": movie[\"title\"],\n",
        "                \"score\": cosine_similarity(query_embedding, movie[\"embedding\"]),\n",
        "            }\n",
        "            for movie in movies\n",
        "        ]\n",
        "\n",
        "        recommendations = sorted(similarities, key=lambda x: x[\"score\"], reverse=True)[:top_k]\n",
        "        return recommendations\n",
        "\n"
      ],
      "metadata": {
        "id": "RAJOXSe96rK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query5 = \"recommend me A love story\"\n",
        "recommendations = recommend_movies(query5)\n",
        "\n",
        "print(\"Top Recommendations:\")\n",
        "for rec in recommendations:\n",
        "    print(f\"Title: {rec['title']}, Similarity Score: {rec['score']}\")\n"
      ],
      "metadata": {
        "id": "cogSPVg18aY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lSyXc_5Q-AhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ez0MaUvYOzCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### App with similarity search"
      ],
      "metadata": {
        "id": "C5OzB6NnzsPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile my_app.py\n",
        "import streamlit as st\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain.chains import GraphCypherQAChain\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from neo4j import GraphDatabase\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "\n",
        "\n",
        "# Initialize Neo4j driver\n",
        "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
        "\n",
        "# Initialize LangChain Neo4jGraph integration\n",
        "kg = Neo4jGraph(uri, username, password, database)\n",
        "\n",
        "# Initialize embedding model\n",
        "embedding_model2 = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Function for cosine similarity\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
        "\n",
        "# Fetch movie embeddings from Neo4j\n",
        "def fetch_movie_embeddings():\n",
        "    cypher = \"\"\"\n",
        "    MATCH (m:Movie)\n",
        "    WHERE m.taglineEmbedding IS NOT NULL\n",
        "    RETURN m.id AS id, m.title AS title, m.taglineEmbedding AS embedding\n",
        "    \"\"\"\n",
        "    results = kg.query(cypher)\n",
        "    return [{\"id\": record[\"id\"], \"title\": record[\"title\"], \"embedding\": record[\"embedding\"]} for record in results]\n",
        "\n",
        "# Recommend movies based on cosine similarity\n",
        "def recommend_movies(query, top_k=5):\n",
        "    query_embedding = embedding_model2.encode(query).tolist()\n",
        "    movies = fetch_movie_embeddings()\n",
        "    similarities = [\n",
        "        {\n",
        "            \"id\": movie[\"id\"],\n",
        "            \"title\": movie[\"title\"],\n",
        "            \"score\": cosine_similarity(query_embedding, movie[\"embedding\"]),\n",
        "        }\n",
        "        for movie in movies\n",
        "    ]\n",
        "    recommendations = sorted(similarities, key=lambda x: x[\"score\"], reverse=True)[:top_k]\n",
        "    return recommendations\n",
        "\n",
        "# Prompt template for Cypher query generation\n",
        "CYPHER_GENERATION_TEMPLATE = \"\"\"Task: Generate Cypher statement to query a graph database.\n",
        "Instructions:\n",
        "Use only the provided relationship types and properties in the schema.\n",
        "Do not use any other relationship types or properties that are not provided.\n",
        "Schema:\n",
        "{schema}\n",
        "Note: Do not include any explanations or apologies in your responses.\n",
        "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
        "Do not include any text except the generated Cypher statement.\n",
        "Examples: Here are a few examples of generated Cypher statements for particular questions:\n",
        "\n",
        "# How many people played in Top Gun?\n",
        "MATCH (m:Movie {{name:\"Top Gun\"}})<-[:ACTED_IN]-()\n",
        "RETURN count(*) AS numberOfActors\n",
        "\n",
        "# What are movies after year 2006?\n",
        "Match (m:Movie)\n",
        "where m.year > 2006\n",
        "Return m.year, m.title\n",
        "\n",
        "# five Movies directed by Ridley Scott\n",
        "MATCH (d:Director)-[:DIRECTED]->(m:Movie)\n",
        "where d.name = \"Ridley Scott\"\n",
        "RETURN m.title, m.year LIMIT 5\n",
        "\n",
        "# Who directed Iron Man?\n",
        "MATCH (d:Director)-[:DIRECTED]->(m:Movie)\n",
        "WHERE m.title = \"Iron Man\"\n",
        "RETURN  m.year, d.name;\n",
        "\n",
        "\n",
        "The question is:\n",
        "{question}\"\"\"\n",
        "\n",
        "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"schema\", \"question\"], template=CYPHER_GENERATION_TEMPLATE\n",
        ")\n",
        "\n",
        "# Initialize Cypher QA Chain\n",
        "chain = GraphCypherQAChain.from_llm(\n",
        "    graph=kg,\n",
        "    cypher_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\"),\n",
        "    qa_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-16k\"),\n",
        "    verbose=True,\n",
        "    allow_dangerous_requests=True,\n",
        ")\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"🎥 Movie Query and Recommendation System\")\n",
        "st.subheader(\"Ask questions about movies or get recommendations!\")\n",
        "\n",
        "# User input\n",
        "query = st.text_input(\"Enter your question or query (e.g., 'Recommend movies like Interstellar')\")\n",
        "\n",
        "if st.button(\"Submit\"):\n",
        "    if query:\n",
        "        if \"recommend\" in query.lower() or \"similar\" in query.lower():\n",
        "            # Handle embedding-based recommendation\n",
        "            st.subheader(\"Recommended Movies Based on Similarity:\")\n",
        "            recommendations = recommend_movies(query)\n",
        "            for rec in recommendations:\n",
        "                st.write(f\"{rec['title']} (Similarity: {rec['score']:.2f})\")\n",
        "        else:\n",
        "            # Handle Cypher-based queries\n",
        "            st.subheader(\"Generated Cypher Query:\")\n",
        "            response = chain.invoke({\"query\": query})\n",
        "            generated_query = response.get(\"query\", \"No query generated.\")\n",
        "            st.code(generated_query, language=\"cypher\")\n",
        "\n",
        "            # Fetch and display results\n",
        "            results = response.get(\"result\", \"No results found.\")\n",
        "            if results and isinstance(results, list):\n",
        "                st.subheader(\"Query Results:\")\n",
        "                for record in results:\n",
        "                    st.write(record)\n",
        "            else:\n",
        "                st.write(results)\n",
        "    else:\n",
        "        st.warning(\"Please enter a valid query.\")\n"
      ],
      "metadata": {
        "id": "5BsKjPXWwLZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Enhanced) App with similarity search"
      ],
      "metadata": {
        "id": "DU3CSpjA-uo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile my_app.py\n",
        "import streamlit as st\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain.chains import GraphCypherQAChain\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from neo4j import GraphDatabase\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "import re\n",
        "\n",
        "# Replace with your Neo4j credentials\n",
        "from google.colab import userdata\n",
        "os.environ[\"NEO_URL\"] = userdata.get('NEO4J_URI')\n",
        "os.environ[\"NEO_USERNAME\"] = userdata.get('NEO4J_USERNAME')\n",
        "os.environ[\"NEO_PASSWORD\"] = userdata.get('NEO4J_PASSWORD')\n",
        "os.environ[\"NEO_DATABASE\"] = userdata.get('NEO4J_DATABASE')\n",
        "\n",
        "uri = os.environ.get(\"NEO_URL\")\n",
        "username = os.environ.get(\"NEO_USERNAME\")\n",
        "password = os.environ.get(\"NEO_PASSWORD\")\n",
        "database = os.environ.get(\"NEO_DATABASE\")\n",
        "\n",
        "# Initialize Neo4j driver\n",
        "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
        "\n",
        "# Initialize LangChain Neo4jGraph integration\n",
        "kg = Neo4jGraph(uri, username, password, database)\n",
        "\n",
        "# Initialize embedding model\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Function for cosine similarity\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
        "\n",
        "# Fetch movie embeddings from Neo4j\n",
        "def fetch_movie_embeddings():\n",
        "    cypher = \"\"\"\n",
        "    MATCH (m:Movie)\n",
        "    WHERE m.taglineEmbedding IS NOT NULL\n",
        "    RETURN m.id AS id, m.title AS title, m.taglineEmbedding AS embedding\n",
        "    \"\"\"\n",
        "    results = kg.query(cypher)\n",
        "    return [{\"id\": record[\"id\"], \"title\": record[\"title\"], \"embedding\": record[\"embedding\"]} for record in results]\n",
        "\n",
        "# Preprocess user query\n",
        "def preprocess_query(query):\n",
        "    stopwords = [\"recommend\", \"movie\", \"similar\", \"movies\", \"show\", \"find\", \"me\", \"please\"]\n",
        "    query = query.lower()\n",
        "    for word in stopwords:\n",
        "        query = query.replace(word, \"\")\n",
        "    query = re.sub(r'\\b\\w\\b', '', query)\n",
        "    query = re.sub(r'\\s+', ' ', query).strip()\n",
        "    query = re.sub(r'[^\\w\\s]', '', query)\n",
        "    return query\n",
        "\n",
        "# Recommend movies based on embeddings\n",
        "def recommend_movies(query, top_k=5):\n",
        "    processed_query = preprocess_query(query)\n",
        "    print(f\"Processed Query: {processed_query}\")\n",
        "\n",
        "    if \"like\" in processed_query:\n",
        "        target_movie = processed_query.split(\"like\")[-1].strip()\n",
        "        print(f\"Target Movie: {target_movie}\")\n",
        "\n",
        "        cypher = f\"\"\"\n",
        "        MATCH (m:Movie)\n",
        "        WHERE toLower(m.title) = toLower(\"{target_movie}\")\n",
        "        RETURN m.id AS id, m.taglineEmbedding AS embedding\n",
        "        \"\"\"\n",
        "        print(f\"Cypher Query to Fetch Target Embedding: {cypher}\")\n",
        "        target_embedding_result = kg.query(cypher)\n",
        "\n",
        "        if not target_embedding_result:\n",
        "            return [{\"title\": f\"Movie '{target_movie}' not found\", \"score\": 0.0}]\n",
        "\n",
        "        target_movie_id = target_embedding_result[0][\"id\"]\n",
        "        target_embedding = target_embedding_result[0][\"embedding\"]\n",
        "        print(f\"Target Movie Embedding: {target_embedding}\")\n",
        "\n",
        "        movies = fetch_movie_embeddings()\n",
        "        filtered_movies = [movie for movie in movies if movie[\"id\"] != target_movie_id]\n",
        "\n",
        "        similarities = [\n",
        "            {\n",
        "                \"id\": movie[\"id\"],\n",
        "                \"title\": movie[\"title\"],\n",
        "                \"score\": cosine_similarity(target_embedding, movie[\"embedding\"]),\n",
        "            }\n",
        "            for movie in filtered_movies\n",
        "        ]\n",
        "\n",
        "        recommendations = sorted(similarities, key=lambda x: x[\"score\"], reverse=True)[:top_k]\n",
        "        return recommendations\n",
        "    else:\n",
        "        query_embedding = embedding_model.encode(processed_query).tolist()\n",
        "        movies = fetch_movie_embeddings()\n",
        "\n",
        "        similarities = [\n",
        "            {\n",
        "                \"id\": movie[\"id\"],\n",
        "                \"title\": movie[\"title\"],\n",
        "                \"score\": cosine_similarity(query_embedding, movie[\"embedding\"]),\n",
        "            }\n",
        "            for movie in movies\n",
        "        ]\n",
        "\n",
        "        recommendations = sorted(similarities, key=lambda x: x[\"score\"], reverse=True)[:top_k]\n",
        "        return recommendations\n",
        "\n",
        "# Cypher Query Generation Prompt\n",
        "CYPHER_GENERATION_TEMPLATE = \"\"\"Task: Generate Cypher statement to query a graph database.\n",
        "Instructions:\n",
        "Use only the provided relationship types and properties in the schema.\n",
        "Do not use any other relationship types or properties that are not provided.\n",
        "Schema:\n",
        "{schema}\n",
        "Note: Do not include any explanations or apologies in your responses.\n",
        "Examples:\n",
        "\n",
        "# How many people played in Top Gun?\n",
        "MATCH (m:Movie {{name:\"Top Gun\"}})<-[:ACTED_IN]-()\n",
        "RETURN count(*) AS numberOfActors\n",
        "\n",
        "# What are movies after year 2006?\n",
        "Match (m:Movie)\n",
        "where m.year > 2006\n",
        "Return m.year, m.title\n",
        "\n",
        "# Movies directed by Ridley Scott\n",
        "MATCH (d:Director)-[:DIRECTED]->(m:Movie)\n",
        "WHERE d.name = \"Ridley Scott\"\n",
        "RETURN m.title, m.year LIMIT 5\n",
        "\n",
        "# Who directed Iron Man?\n",
        "MATCH (d:Director)-[:DIRECTED]->(m:Movie)\n",
        "WHERE m.title = \"Iron Man\"\n",
        "RETURN m.year, d.name\n",
        "\n",
        "The question is:\n",
        "{question}\"\"\"\n",
        "\n",
        "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"schema\", \"question\"], template=CYPHER_GENERATION_TEMPLATE\n",
        ")\n",
        "\n",
        "# Initialize Cypher QA Chain\n",
        "chain = GraphCypherQAChain.from_llm(\n",
        "    graph=kg,\n",
        "    cypher_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\"),\n",
        "    qa_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-16k\"),\n",
        "    verbose=True,\n",
        "    allow_dangerous_requests=True,\n",
        ")\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"🎥 Movie Query and Recommendation System\")\n",
        "st.subheader(\"Ask questions about movies or get recommendations!\")\n",
        "\n",
        "query = st.text_input(\"Enter your query (e.g., 'Recommend movies like Interstellar')\")\n",
        "\n",
        "if st.button(\"Submit\"):\n",
        "    if query:\n",
        "        if \"recommend\" in query.lower() or \"similar\" in query.lower():\n",
        "            st.subheader(\"Recommended Movies Based on Similarity:\")\n",
        "            recommendations = recommend_movies(query)\n",
        "            for rec in recommendations:\n",
        "                st.write(f\"{rec['title']} (Similarity: {rec['score']:.6f})\")\n",
        "        else:\n",
        "            st.subheader(\"Generated Cypher Query:\")\n",
        "            response = chain.invoke({\"query\": query})\n",
        "            generated_query = response.get(\"query\", \"No query generated.\")\n",
        "            st.code(generated_query, language=\"cypher\")\n",
        "            results = response.get(\"result\", \"No results found.\")\n",
        "            if results and isinstance(results, list):\n",
        "                st.subheader(\"Query Results:\")\n",
        "                for record in results:\n",
        "                    st.write(record)\n",
        "            else:\n",
        "                st.write(results)\n",
        "    else:\n",
        "        st.warning(\"Please enter a valid query.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pplYYTu-uND",
        "outputId": "f5143589-043a-4bf4-fae9-f880e466ac4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting my_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "schema = kg.get_structured_schema\n",
        "print(f\"Schema Length: {len(schema)} characters\")\n"
      ],
      "metadata": {
        "id": "oj5yPRDFXYuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0LUa-c3Gfs-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run my_app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "Atn1Vrt7pA-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding Memory to RAG app (with similiarity search)"
      ],
      "metadata": {
        "id": "WMx4kmQAiwsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade streamlit\n"
      ],
      "metadata": {
        "id": "URgniFV2jzZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile my_app_with_mem.py\n",
        "import streamlit as st\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain.chains import GraphCypherQAChain\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from neo4j import GraphDatabase\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "import re\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "uri = st.secrets[\"NEO4J_URI\"]\n",
        "username = st.secrets[\"NEO4J_USERNAME\"]\n",
        "password = st.secrets[\"NEO4J_PASSWORD\"]\n",
        "TMDB_API_KEY = st.secrets[\"TMDB_API\"]\n",
        "database = st.secrets[\"NEO4J_DATABASE\"]\n",
        "openai_key = st.secrets[\"OPENAI_API_KEY\"]\n",
        "# Initialize Neo4j driver\n",
        "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
        "\n",
        "# Initialize LangChain Neo4jGraph integration\n",
        "kg = Neo4jGraph(uri, username, password, database)\n",
        "\n",
        "# Initialize embedding model\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Initialize memory for conversational context\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\",return_messages=True)\n",
        "#memory = ConversationBufferMemory(k=3, return_messages=True)\n",
        "\n",
        "# Function for cosine similarity\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
        "\n",
        "def fetch_movie_embeddings():\n",
        "    cypher = \"\"\"\n",
        "    MATCH (m:Movie)\n",
        "    WHERE m.taglineEmbedding IS NOT NULL\n",
        "    RETURN m.id AS id, m.title AS title, m.taglineEmbedding AS embedding\n",
        "    \"\"\"\n",
        "    results = kg.query(cypher)\n",
        "    return [{\"id\": record[\"id\"], \"title\": record[\"title\"], \"embedding\": record[\"embedding\"]} for record in results]\n",
        "\n",
        "# Preprocess user query\n",
        "def preprocess_query(query):\n",
        "    stopwords = [\"recommend\", \"movie\", \"similar\", \"movies\", \"show\", \"find\", \"me\", \"please\"]\n",
        "    query = query.lower()\n",
        "    for word in stopwords:\n",
        "        query = query.replace(word, \"\")\n",
        "    query = re.sub(r'\\b\\w\\b', '', query)\n",
        "    query = re.sub(r'\\s+', ' ', query).strip()\n",
        "    query = re.sub(r'[^\\w\\s]', '', query)\n",
        "    return query\n",
        "\n",
        "# Recommend movies based on embeddings\n",
        "from fuzzywuzzy import process  # Install using pip install fuzzywuzzy\n",
        "\n",
        "def recommend_movies(query, top_k=5):\n",
        "    # Fetch all movies and their embeddings\n",
        "    movies = fetch_movie_embeddings()\n",
        "    available_titles = [movie[\"title\"] for movie in movies]\n",
        "\n",
        "    # Preprocess query\n",
        "    processed_query = preprocess_query(query)\n",
        "\n",
        "    # Extract the target movie from the query\n",
        "    if \"like\" in processed_query:\n",
        "        target_movie = processed_query.split(\"like\")[-1].strip()\n",
        "        # Use fuzzy matching to find the best match\n",
        "        matched_title, similarity = process.extractOne(target_movie, available_titles)\n",
        "\n",
        "        if similarity < 80:  # Threshold for a \"good match\"\n",
        "            return [{\"title\": f\"No close matches found for '{target_movie}'. Did you mean '{matched_title}'?\", \"score\": 0.0}]\n",
        "\n",
        "        # Fetch the embedding for the matched title\n",
        "        target_embedding = next(\n",
        "            (movie[\"embedding\"] for movie in movies if movie[\"title\"] == matched_title), None\n",
        "        )\n",
        "        if not target_embedding:\n",
        "            return [{\"title\": f\"Movie '{matched_title}' not found in the database.\", \"score\": 0.0}]\n",
        "\n",
        "        # Calculate similarity with other movies\n",
        "        similarities = [\n",
        "            {\n",
        "                \"title\": movie[\"title\"],\n",
        "                \"score\": cosine_similarity(target_embedding, movie[\"embedding\"]),\n",
        "            }\n",
        "            for movie in movies if movie[\"title\"] != matched_title\n",
        "        ]\n",
        "\n",
        "        # Sort and return top recommendations\n",
        "        return sorted(similarities, key=lambda x: x[\"score\"], reverse=True)[:top_k]\n",
        "\n",
        "    else:\n",
        "        query_embedding = embedding_model.encode(processed_query).tolist()\n",
        "\n",
        "        # Calculate similarity with all movies\n",
        "        similarities = [\n",
        "            {\n",
        "                \"title\": movie[\"title\"],\n",
        "                \"score\": cosine_similarity(query_embedding, movie[\"embedding\"]),\n",
        "            }\n",
        "            for movie in movies\n",
        "        ]\n",
        "\n",
        "        return sorted(similarities, key=lambda x: x[\"score\"], reverse=True)[:top_k]\n",
        "\n",
        "\n",
        "# Cypher Query Generation Prompt\n",
        "CYPHER_GENERATION_TEMPLATE = \"\"\"Task: Generate Cypher statement to query a graph database.\n",
        "Instructions:\n",
        "Use only the provided relationship types and properties in the schema.\n",
        "Do not use any other relationship types or properties that are not provided.\n",
        "Schema:\n",
        "{schema}\n",
        "Note: Do not include any explanations or apologies in your responses.\n",
        "Examples:\n",
        "\n",
        "# How many people played in Top Gun?\n",
        "MATCH (m:Movie {{name:\"Top Gun\"}})<-[:ACTED_IN]-()\n",
        "RETURN count(*) AS numberOfActors\n",
        "\n",
        "# What are movies after year 2006?\n",
        "Match (m:Movie)\n",
        "where m.year > 2006\n",
        "Return m.year, m.title\n",
        "\n",
        "# Movies directed by Ridley Scott\n",
        "MATCH (d:Director)-[:DIRECTED]->(m:Movie)\n",
        "WHERE d.name = \"Ridley Scott\"\n",
        "RETURN m.title, m.year LIMIT 5\n",
        "\n",
        "# Who directed Iron Man?\n",
        "MATCH (d:Director)-[:DIRECTED]->(m:Movie)\n",
        "WHERE m.title = \"Iron Man\"\n",
        "RETURN m.year, d.name\n",
        "\n",
        "The question is:\n",
        "{question}\"\"\"\n",
        "\n",
        "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"schema\", \"question\"], template=CYPHER_GENERATION_TEMPLATE\n",
        ")\n",
        "\n",
        "# Initialize Cypher QA Chain\n",
        "chain = GraphCypherQAChain.from_llm(\n",
        "    graph=kg,\n",
        "    cypher_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\"),\n",
        "    qa_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-16k\"),\n",
        "    memory=memory,\n",
        "    verbose=True,\n",
        "    allow_dangerous_requests=True,\n",
        ")\n",
        "#chain.invoke({\"query\":\"Movie similar to Inferno\"})\n",
        "#chain.invoke({\"query\":\"recommend movie like Intersteller\"})\n",
        "# Streamlit UI\n",
        "st.title(\"🎥 Movie Chatbot with Memory\")\n",
        "st.subheader(\"Ask questions about movies or get recommendations!\")\n",
        "if \"input\" not in st.session_state:\n",
        "    st.session_state.input = \"\"  # Initialize input during the first load\n",
        "\n",
        "\n",
        "# Initialize session state variables\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "if \"memory\" not in st.session_state:\n",
        "    st.session_state.memory = {\"last_movie\": None, \"last_director\": None}\n",
        "\n",
        "# # Display past messages\n",
        "# for message in st.session_state.messages:\n",
        "#     if message[\"role\"] == \"user\":\n",
        "#         st.markdown(f\"**You:** {message['content']}\")\n",
        "#     else:\n",
        "#         st.markdown(f\"**Bot:** {message['content']}\")\n",
        "\n",
        "# Function to extract and update context for movies or directors\n",
        "def extract_and_update_context(query, response):\n",
        "    \"\"\"\n",
        "    Extracts relevant context (e.g., director, movie) from the query and response\n",
        "    and updates the memory.\n",
        "    \"\"\"\n",
        "    # Handle director-related responses\n",
        "    if \"directed\" in response.lower():\n",
        "        # Extract the director's name from the response\n",
        "        parts = response.split(\"directed\")\n",
        "        if len(parts) > 1:\n",
        "            director = parts[0].strip()  # Extract name before \"directed\"\n",
        "            st.session_state.memory[\"last_director\"] = director\n",
        "\n",
        "    # Handle movie recommendation queries\n",
        "    if \"recommend\" in query.lower() or \"similar\" in query.lower():\n",
        "        if \"like\" in query.lower():\n",
        "            # Extract the target movie from the query\n",
        "            target_movie = query.split(\"like\")[-1].strip()\n",
        "            st.session_state.memory[\"last_movie\"] = target_movie\n",
        "\n",
        "\n",
        "\n",
        "# Function to handle ambiguous queries\n",
        "def handle_context_based_query(query):\n",
        "    \"\"\"\n",
        "    Handles queries that rely on contextual memory, such as pronouns.\n",
        "    \"\"\"\n",
        "    # Handle \"like this/it\" for movies\n",
        "    if \"like this\" in query.lower() or \"like it\" in query.lower():\n",
        "        last_movie = st.session_state.memory.get(\"last_movie\", None)\n",
        "        if last_movie:\n",
        "            recommendations = recommend_movies(f\"recommend me movie like {last_movie}\")\n",
        "            return \"\\n\".join([f\"- {rec['title']} (Similarity: {rec['score']:.6f})\" for rec in recommendations])\n",
        "        else:\n",
        "            return \"I'm sorry, I don't know what you're referring to. Could you specify the movie?\"\n",
        "\n",
        "    # Handle \"from him\" for directors\n",
        "    if \"from him\" in query.lower() or \"from her\" in query.lower() or \"from them\" in query.lower():\n",
        "        last_director = st.session_state.memory.get(\"last_director\", None)\n",
        "        if last_director:\n",
        "            # Query Neo4j for movies directed by the last tracked director\n",
        "            cypher = f\"\"\"\n",
        "            MATCH (d:Director {{name: \"{last_director}\"}})-[:DIRECTED]->(m:Movie)\n",
        "            RETURN m.title AS title\n",
        "            \"\"\"\n",
        "            results = kg.query(cypher)\n",
        "            if results:\n",
        "                return \"\\n\".join([record[\"title\"] for record in results])\n",
        "            else:\n",
        "                return f\"I couldn't find any movies directed by {last_director}.\"\n",
        "        else:\n",
        "            return \"I'm sorry, I don't know who you're referring to. Could you clarify?\"\n",
        "\n",
        "    return None  # Not a context-based query\n",
        "\n",
        "\n",
        "# Function to handle query submission and clear input\n",
        "def handle_query():\n",
        "    \"\"\"\n",
        "    Handles user queries and updates session state with bot responses.\n",
        "    \"\"\"\n",
        "    query = st.session_state.get(\"input\", \"\").strip()  # Access user input\n",
        "    if query:  # Proceed only if the input is not empty\n",
        "        # Ensure query is added only once\n",
        "        if not st.session_state.messages or st.session_state.messages[-1] != {\"role\": \"user\", \"content\": query}:\n",
        "            st.session_state.messages.append({\"role\": \"user\", \"content\": query})\n",
        "\n",
        "            # Generate bot response\n",
        "            response = handle_context_based_query(query)\n",
        "            if not response:  # If no context-based response, proceed as usual\n",
        "                with st.spinner(\"Thinking...\"):\n",
        "                    if \"recommend\" in query.lower() or \"similar\" in query.lower():\n",
        "                        recommendations = recommend_movies(query)\n",
        "                        response = \"\\n\".join(\n",
        "                            [f\"- {rec['title']} (Similarity: {rec['score']:.6f})\" for rec in recommendations]\n",
        "                        )\n",
        "                    else:\n",
        "                        try:\n",
        "                            result = chain.invoke({\"query\": query})\n",
        "                            generated_query = result.get(\"query\", \"No query generated.\")\n",
        "                            st.code(generated_query, language=\"cypher\")\n",
        "                            response = result.get(\"result\", \"No results found.\")\n",
        "                        except Exception as e:\n",
        "                            response = f\"An error occurred: {e}\"\n",
        "\n",
        "            # Extract and store context for follow-up queries\n",
        "            extract_and_update_context(query, response)\n",
        "\n",
        "            # Append bot response only once\n",
        "            if not st.session_state.messages or st.session_state.messages[-1] != {\"role\": \"bot\", \"content\": response}:\n",
        "                st.session_state.messages.append({\"role\": \"bot\", \"content\": response})\n",
        "\n",
        "        # Clear input field for next query\n",
        "        st.session_state.input = \"\"\n",
        "\n",
        "\n",
        "# def display_chat_history():\n",
        "#     \"\"\"\n",
        "#     Renders the chat history stored in `st.session_state.messages`.\n",
        "#     \"\"\"\n",
        "#     # Use a single loop to iterate and display messages\n",
        "#     for i, message in enumerate(st.session_state.messages):\n",
        "#         if message[\"role\"] == \"user\":\n",
        "#             st.markdown(f\"**You:** {message['content']}\")\n",
        "#         else:\n",
        "#             st.markdown(f\"**Bot:** {message['content']}\")\n",
        "\n",
        "\n",
        "# # Main Streamlit app logic\n",
        "# st.title(\"🎥 Movie Chatbot with Memory\")\n",
        "# st.subheader(\"Ask questions about movies or get recommendations!\")\n",
        "\n",
        "# # Initialize session state variables\n",
        "# if \"messages\" not in st.session_state:\n",
        "#     st.session_state.messages = []\n",
        "\n",
        "# if \"memory\" not in st.session_state:\n",
        "#     st.session_state.memory = {\"last_movie\": None, \"last_director\": None}\n",
        "\n",
        "# Chat input field linked to `st.session_state.input`\n",
        "# Display chat history\n",
        "\n",
        "\n",
        "st.text_input(\n",
        "    \"Type your message:\",\n",
        "    placeholder=\"Type your question here...\",\n",
        "    value=st.session_state.get(\"input\", \"\"),  # Default to empty string\n",
        "    key=\"input\",\n",
        "    on_change=lambda:handle_query()  # Trigger `handle_query` when the input changes\n",
        ")\n",
        "\n",
        "for message in st.session_state.messages:\n",
        "    if message[\"role\"] == \"user\":\n",
        "        st.markdown(f\"**You:** {message['content']}\")\n",
        "    else:\n",
        "        st.markdown(f\"**Bot:** {message['content']}\")\n",
        "# Display chat history only once\n",
        "#display_chat_history()\n",
        "\n",
        "# Optional: Debugging information in the sidebar\n",
        "st.sidebar.write(\"**Tracked Context (Debugging):**\", st.session_state.memory)\n"
      ],
      "metadata": {
        "id": "hwf_woMNi5AT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run my_app_with_mem.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "tk3pU05wOay4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q fuzzywuzzy"
      ],
      "metadata": {
        "id": "qY7l_wns5Ivy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#chain.invoke({\"query\":\"Movie similar to Inferno\"})\n",
        "chain.invoke({\"query\":\"recommend movie like Intersteller\"})"
      ],
      "metadata": {
        "id": "AOFZtW--LZ8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(c) adding memeory and fethcing poster\n",
        "this is not working need to fix it"
      ],
      "metadata": {
        "id": "79E-LjRrCJaa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zvF938j8TG3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile my_app_third.py\n",
        "import streamlit as st\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain.chains import GraphCypherQAChain\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from neo4j import GraphDatabase\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "import re\n",
        "from fuzzywuzzy import process\n",
        "import requests\n",
        "uri = st.secrets[\"NEO4J_URI\"]\n",
        "username = st.secrets[\"NEO4J_USERNAME\"]\n",
        "password = st.secrets[\"NEO4J_PASSWORD\"]\n",
        "TMDB_API_KEY = st.secrets[\"TMDB_API\"]\n",
        "database = st.secrets[\"NEO4J_DATABASE\"]\n",
        "openai_key = st.secrets[\"OPENAI_API_KEY\"]\n",
        "# Initialize Neo4j driver\n",
        "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
        "\n",
        "# Initialize LangChain Neo4jGraph integration\n",
        "kg = Neo4jGraph(uri, username, password, database)\n",
        "\n",
        "# Initialize embedding model\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Initialize memory for conversational context\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Function for cosine similarity\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
        "\n",
        "@st.cache_data\n",
        "def fetch_movie_embeddings():\n",
        "    cypher = \"\"\"\n",
        "    MATCH (m:Movie)\n",
        "    WHERE m.taglineEmbedding IS NOT NULL\n",
        "    RETURN m.id AS id, m.title AS title, m.taglineEmbedding AS embedding\n",
        "    \"\"\"\n",
        "    results = kg.query(cypher)\n",
        "    return [{\"id\": record[\"id\"], \"title\": record[\"title\"], \"embedding\": record[\"embedding\"]} for record in results]\n",
        "\n",
        "# Preprocess user query\n",
        "def preprocess_query(query):\n",
        "    stopwords = [\"recommend\", \"movie\", \"similar\", \"movies\", \"show\", \"find\", \"me\", \"please\"]\n",
        "    query = query.lower()\n",
        "    for word in stopwords:\n",
        "        query = query.replace(word, \"\")\n",
        "    query = re.sub(r'\\b\\w\\b', '', query)\n",
        "    query = re.sub(r'\\s+', ' ', query).strip()\n",
        "    query = re.sub(r'[^\\w\\s]', '', query)\n",
        "    return query\n",
        "\n",
        "# Recommend movies based on embeddings\n",
        "@st.cache_data\n",
        "def recommend_movies(query, top_k=5):\n",
        "    # Fetch all movies and their embeddings\n",
        "    movies = fetch_movie_embeddings()\n",
        "    available_titles = [movie[\"title\"] for movie in movies]\n",
        "\n",
        "    # Preprocess query\n",
        "    processed_query = preprocess_query(query)\n",
        "\n",
        "    # Extract the target movie from the query\n",
        "    if \"like\" in processed_query:\n",
        "        target_movie = processed_query.split(\"like\")[-1].strip()\n",
        "        # Use fuzzy matching to find the best match\n",
        "        matched_title, similarity = process.extractOne(target_movie, available_titles)\n",
        "\n",
        "        if similarity < 80:  # Threshold for a \"good match\"\n",
        "            return [{\"title\": f\"No close matches found for '{target_movie}'. Did you mean '{matched_title}'?\", \"score\": 0.0}]\n",
        "\n",
        "        # Fetch the embedding for the matched title\n",
        "        target_embedding = next(\n",
        "            (movie[\"embedding\"] for movie in movies if movie[\"title\"] == matched_title), None\n",
        "        )\n",
        "        if not target_embedding:\n",
        "            return [{\"title\": f\"Movie '{matched_title}' not found in the database.\", \"score\": 0.0}]\n",
        "\n",
        "        # Calculate similarity with other movies\n",
        "        similarities = [\n",
        "            {\n",
        "                \"title\": movie[\"title\"],\n",
        "                \"score\": cosine_similarity(target_embedding, movie[\"embedding\"]),\n",
        "            }\n",
        "            for movie in movies if movie[\"title\"] != matched_title\n",
        "        ]\n",
        "\n",
        "        # Sort and return top recommendations\n",
        "        return sorted(similarities, key=lambda x: x[\"score\"], reverse=True)[:top_k]\n",
        "\n",
        "    else:\n",
        "        query_embedding = embedding_model.encode(processed_query).tolist()\n",
        "\n",
        "        # Calculate similarity with all movies\n",
        "        similarities = [\n",
        "            {\n",
        "                \"title\": movie[\"title\"],\n",
        "                \"score\": cosine_similarity(query_embedding, movie[\"embedding\"]),\n",
        "            }\n",
        "            for movie in movies\n",
        "        ]\n",
        "\n",
        "        return sorted(similarities, key=lambda x: x[\"score\"], reverse=True)[:top_k]\n",
        "\n",
        "# Cypher Query Generation Prompt\n",
        "CYPHER_GENERATION_TEMPLATE = \"\"\"Task: Generate Cypher statement to query a graph database.\n",
        "Instructions:\n",
        "Use only the provided relationship types and properties in the schema.\n",
        "Do not use any other relationship types or properties that are not provided.\n",
        "Schema:\n",
        "{schema}\n",
        "Note: Do not include any explanations or apologies in your responses.\n",
        "Examples:\n",
        "\n",
        "# How many people played in Top Gun?\n",
        "MATCH (m:Movie {{name:\"Top Gun\"}})<-[:ACTED_IN]-()\n",
        "RETURN count(*) AS numberOfActors\n",
        "\n",
        "# What are movies after year 2006?\n",
        "Match (m:Movie)\n",
        "where m.year > 2006\n",
        "Return m.year, m.title\n",
        "\n",
        "# Movies directed by Ridley Scott\n",
        "MATCH (d:Director)-[:DIRECTED]->(m:Movie)\n",
        "WHERE d.name = \"Ridley Scott\"\n",
        "RETURN m.title, m.year LIMIT 5\n",
        "\n",
        "# Who directed Iron Man?\n",
        "MATCH (d:Director)-[:DIRECTED]->(m:Movie)\n",
        "WHERE m.title = \"Iron Man\"\n",
        "RETURN m.year, d.name\n",
        "\n",
        "The question is:\n",
        "{question}\"\"\"\n",
        "\n",
        "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"schema\", \"question\"], template=CYPHER_GENERATION_TEMPLATE\n",
        ")\n",
        "\n",
        "# Initialize Cypher QA Chain\n",
        "chain = GraphCypherQAChain.from_llm(\n",
        "    graph=kg,\n",
        "    cypher_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\"),\n",
        "    qa_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-16k\"),\n",
        "    memory=memory,\n",
        "    verbose=True,\n",
        "    allow_dangerous_requests=True,\n",
        ")\n",
        "# Fetch posters from TMDb\n",
        "def fetch_movie_poster(movie_name):\n",
        "    url = f\"https://api.themoviedb.org/3/search/movie?api_key={TMDB_API_KEY}&query={movie_name}\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        results = response.json().get(\"results\", [])\n",
        "        if results and \"poster_path\" in results[0]:\n",
        "            poster_path = results[0][\"poster_path\"]\n",
        "            return f\"https://image.tmdb.org/t/p/w500{poster_path}\"\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching poster for {movie_name}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# if recommendations:\n",
        "#     for rec in recommendations:\n",
        "#         poster_url = fetch_movie_poster(rec['title'])\n",
        "#         st.image(poster_url, width=100, caption=rec['title'])\n",
        "\n",
        "\n",
        "# Function to extract and update context for movies or directors\n",
        "def extract_and_update_context(query, response):\n",
        "    \"\"\"\n",
        "    Extracts relevant context (e.g., director, movie) from the query and response\n",
        "    and updates the memory.\n",
        "    \"\"\"\n",
        "    # Handle director-related responses\n",
        "    if \"directed\" in response.lower():\n",
        "        # Extract the director's name from the response\n",
        "        parts = response.split(\"directed\")\n",
        "        if len(parts) > 1:\n",
        "            director = parts[0].strip()  # Extract name before \"directed\"\n",
        "            st.session_state.memory[\"last_director\"] = director\n",
        "\n",
        "    # Handle movie recommendation queries\n",
        "    if \"recommend\" in query.lower() or \"similar\" in query.lower():\n",
        "        if \"like\" in query.lower():\n",
        "            # Extract the target movie from the query\n",
        "            target_movie = query.split(\"like\")[-1].strip()\n",
        "            st.session_state.memory[\"last_movie\"] = target_movie\n",
        "\n",
        "# Function to handle ambiguous queries\n",
        "def handle_context_based_query(query):\n",
        "    \"\"\"\n",
        "    Handles queries that rely on contextual memory, such as pronouns.\n",
        "    \"\"\"\n",
        "    # Handle \"like this/it\" for movies\n",
        "    if \"like this\" in query.lower() or \"like it\" in query.lower():\n",
        "        last_movie = st.session_state.memory.get(\"last_movie\", None)\n",
        "        if last_movie:\n",
        "            recommendations = recommend_movies(f\"recommend me movie like {last_movie}\")\n",
        "            return \"\\n\".join([f\"- {rec['title']} (Similarity: {rec['score']:.6f})\" for rec in recommendations])\n",
        "        else:\n",
        "            return \"I'm sorry, I don't know what you're referring to. Could you specify the movie?\"\n",
        "\n",
        "    # Handle \"from him\" for directors\n",
        "    if \"from him\" in query.lower() or \"from her\" in query.lower() or \"from them\" in query.lower():\n",
        "        last_director = st.session_state.memory.get(\"last_director\", None)\n",
        "        if last_director:\n",
        "            # Query Neo4j for movies directed by the last tracked director\n",
        "            cypher = f\"\"\"\n",
        "            MATCH (d:Director {{name: \"{last_director}\"}})-[:DIRECTED]->(m:Movie)\n",
        "            RETURN m.title AS title\n",
        "            \"\"\"\n",
        "            results = kg.query(cypher)\n",
        "            if results:\n",
        "                return \"\\n\".join([record[\"title\"] for record in results])\n",
        "            else:\n",
        "                return f\"I couldn't find any movies directed by {last_director}.\"\n",
        "        else:\n",
        "            return \"I'm sorry, I don't know who you're referring to. Could you clarify?\"\n",
        "\n",
        "    return None  # Not a context-based query\n",
        "\n",
        "# Function to handle query submission and clear input\n",
        "def handle_query():\n",
        "    \"\"\"\n",
        "    Handles user queries and updates session state with bot responses.\n",
        "    \"\"\"\n",
        "    query = st.session_state.get(\"input\", \"\").strip()  # Access user input\n",
        "    if not query:  # Proceed only if the input is not empty\n",
        "        return\n",
        "\n",
        "    # Ensure query is added only once\n",
        "    if not st.session_state.messages or st.session_state.messages[-1] != {\"role\": \"user\", \"content\": query}:\n",
        "        st.session_state.messages.append({\"role\": \"user\", \"content\": query})\n",
        "\n",
        "        # Generate bot response\n",
        "        response = handle_context_based_query(query)\n",
        "        if not response:  # If no context-based response, proceed as usual\n",
        "            with st.spinner(\"Thinking...\"):\n",
        "                response = generate_response(query)\n",
        "\n",
        "        # Extract and store context for follow-up queries\n",
        "        extract_and_update_context(query, response)\n",
        "\n",
        "        # Append bot response only once\n",
        "        if not st.session_state.messages or st.session_state.messages[-1] != {\"role\": \"bot\", \"content\": response}:\n",
        "            st.session_state.messages.append({\"role\": \"bot\", \"content\": response})\n",
        "\n",
        "    # Clear input field for next query\n",
        "    st.session_state.input = \"\"\n",
        "\n",
        "# def generate_response(query):\n",
        "#     \"\"\"\n",
        "#     Generates a response based on the user query.\n",
        "#     \"\"\"\n",
        "#     if \"recommend\" in query.lower() or \"similar\" in query.lower():\n",
        "#         recommendations = recommend_movies(query)\n",
        "#         return \"\\n\".join([f\"- {rec['title']} (Similarity: {rec['score']:.6f})\" for rec in recommendations])\n",
        "#     else:\n",
        "#         try:\n",
        "#             result = chain.invoke({\"query\": query})\n",
        "#             generated_query = result.get(\"query\", \"No query generated.\")\n",
        "#             st.code(generated_query, language=\"cypher\")\n",
        "#             return result.get(\"result\", \"No results found.\")\n",
        "#         except Exception as e:\n",
        "#             return f\"An error occurred: {e}\"\n",
        "def generate_response(query):\n",
        "    if \"recommend\" in query.lower() or \"similar\" in query.lower():\n",
        "        recommendations = recommend_movies(query)\n",
        "        cols = st.columns(5)\n",
        "        for idx, rec in enumerate(recommendations):\n",
        "            with cols[idx % 5]:\n",
        "                poster_url = fetch_movie_poster(rec[\"title\"])\n",
        "                if poster_url:\n",
        "                    st.image(poster_url, caption=f\"{rec['title']} (Similarity: {rec['score']:.6f})\", use_column_width=True)\n",
        "                else:\n",
        "                    st.write(f\"{rec['title']} (Similarity: {rec['score']:.6f}) - No poster available\")\n",
        "    else:\n",
        "        st.subheader(\"Generated Cypher Query:\")\n",
        "        response = chain.invoke({\"query\": query})\n",
        "        generated_query = response.get(\"query\", \"No query generated.\")\n",
        "        st.code(generated_query, language=\"cypher\")\n",
        "        results = response.get(\"result\", \"No results found.\")\n",
        "        if results:\n",
        "            st.write(results)\n",
        "\n",
        "# Streamlit UI\n",
        "# Main Streamlit UI\n",
        "st.title(\"🎥 Movie Chatbot with Memory\")\n",
        "st.markdown(\"**📢 Ask questions about movies or get recommendations!**\")\n",
        "if \"input\" not in st.session_state:\n",
        "    st.session_state.input = \"\"  # Initialize input during the first load\n",
        "\n",
        "\n",
        "# Initialize session state variables\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "if \"memory\" not in st.session_state:\n",
        "    st.session_state.memory = {\"last_movie\": None, \"last_director\": None}\n",
        "# Sidebar options\n",
        "with st.sidebar:\n",
        "    st.title(\"🎬 Options\")\n",
        "    if st.button(\"Clear Chat History\"):\n",
        "        st.session_state.messages = []\n",
        "        st.rerun()\n",
        "    st.markdown(\"**Instructions:**\\n- Ask questions like:\\n  - Who directed Interstellar?\\n  - Recommend movies like Inception.\")\n",
        "\n",
        "# Chat input field\n",
        "query = st.text_area(\n",
        "    \"💬 Your Question:\",\n",
        "    placeholder=\"Ask about movies, directors, or get recommendations...\",\n",
        "    value=st.session_state.get(\"input\", \"\"),\n",
        "    key=\"input\",\n",
        "    on_change=handle_query\n",
        ")\n",
        "\n",
        "\n",
        "# Display chat history\n",
        "st.markdown(\"### 💬 Conversation History\")\n",
        "for message in st.session_state.messages:\n",
        "    if message[\"role\"] == \"user\":\n",
        "        st.markdown(f'<div style=\"text-align: right; background-color: #dcf8c6; padding: 8px; border-radius: 10px; margin: 5px;\">{message[\"content\"]}</div>', unsafe_allow_html=True)\n",
        "    else:\n",
        "        st.markdown(f'<div style=\"text-align: left; background-color: #f1f0f0; padding: 8px; border-radius: 10px; margin: 5px;\">{message[\"content\"]}</div>', unsafe_allow_html=True)\n",
        "\n",
        "# Debugging information\n",
        "with st.expander(\"🔍 Debugging Information\"):\n",
        "    st.write(\"**Context Memory:**\", st.session_state.memory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQKuldYxCIx8",
        "outputId": "d1bc00b4-b845-43c5-f04a-12ff4187555d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing my_app_third.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run my_app_third.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBjrDSzUCZPP",
        "outputId": "de42a83e-ef70-4f5d-a47f-5d5056e185a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.106.63.128\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://eighty-buttons-scream.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0olpcnDFCYJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install gradio\n",
        "import gradio as gr\n",
        "\n",
        "def greet(name):\n",
        "    return f\"Hello {name}!\"\n",
        "\n",
        "iface = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "_6I1drXPQGty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## App without similarity search"
      ],
      "metadata": {
        "id": "4lc5kvLZzx8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile my_app.py\n",
        "\n",
        "import streamlit as st\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from neo4j import GraphDatabase\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "from langchain.chains import GraphCypherQAChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "import textwrap\n",
        "\n",
        "# Replace with your Neo4j credentials\n",
        "uri = os.environ.get(\"NEO_URL\")\n",
        "username = os.environ.get(\"NEO_USERNAME\")\n",
        "password = os.environ.get(\"NEO_PASSWORD\")\n",
        "database = os.environ.get(\"NEO_DATABASE\")\n",
        "\n",
        "# Initialize Neo4j driver\n",
        "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
        "\n",
        "#Initialize a knowledge graph instance using LangChain's Neo4j integration\n",
        "kg = Neo4jGraph(\n",
        "    uri, username, password, database\n",
        ")\n",
        "\n",
        "# Prompt Template for Cypher Query Generation\n",
        "CYPHER_GENERATION_TEMPLATE = \"\"\"Task:Generate Cypher statement to query a graph database.\n",
        "Instructions:\n",
        "Use only the provided relationship types and properties in the schema.\n",
        "Do not use any other relationship types or properties that are not provided.\n",
        "Schema:\n",
        "{schema}\n",
        "Note: Do not include any explanations or apologies in your responses.\n",
        "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
        "Do not include any text except the generated Cypher statement.\n",
        "Examples: Here are a few examples of generated Cypher statements for particular questions:\n",
        "\n",
        "# How many people played in Top Gun?\n",
        "MATCH (m:Movie {{name:\"Top Gun\"}})<-[:ACTED_IN]-()\n",
        "RETURN count(*) AS numberOfActors\n",
        "\n",
        "# What are movies after year 2006?\n",
        "Match (m:Movie)\n",
        "where m.year > 2006\n",
        "Return m.year, m.title\n",
        "The question is:\n",
        "{question}\"\"\"\n",
        "\n",
        "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"schema\", \"question\"], template=CYPHER_GENERATION_TEMPLATE\n",
        ")\n",
        "\n",
        "# Initialize the GraphCypherQAChain\n",
        "chain = GraphCypherQAChain.from_llm(\n",
        "    graph=kg,\n",
        "    cypher_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\"),\n",
        "    qa_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-16k\"),\n",
        "    verbose=True,\n",
        "    allow_dangerous_requests=True,\n",
        ")\n",
        "\n",
        "# Function to run the chain and format the response\n",
        "def prettyCypherChain(question: str) -> str:\n",
        "    \"\"\"Runs the cypherChain and formats the response.\"\"\"\n",
        "    response = chain.run(question)\n",
        "\n",
        "    if isinstance(response, str):  # Check if response is a string\n",
        "        st.write(textwrap.fill(response, 60))\n",
        "    elif isinstance(response, dict):  # Check if response is a dictionary\n",
        "        for key, value in response.items():\n",
        "            st.write(f\"{key}: {value}\")\n",
        "    elif isinstance(response, list):  # Check if response is a list\n",
        "        # Create a DataFrame for better display in Streamlit\n",
        "        import pandas as pd\n",
        "        df = pd.DataFrame(response)\n",
        "        st.dataframe(df)\n",
        "    else:\n",
        "        st.write(response) # Print the response as is if it's not a string, dictionary, or list\n",
        "# Streamlit App\n",
        "def main():\n",
        "    st.title(\"Neo4j Movie Recommendation App\")\n",
        "    question = st.text_input(\"Enter your question about movies:\")\n",
        "\n",
        "    if st.button(\"Get Answer\"):\n",
        "        if question:\n",
        "            st.write(\"**Question:**\", question)\n",
        "            with st.spinner(\"Generating Cypher query and fetching results...\"):\n",
        "                try:\n",
        "                    prettyCypherChain(question)\n",
        "                except Exception as e:\n",
        "                    st.error(f\"An error occurred: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "_EfzdEAxz2k0",
        "outputId": "1e528910-9422-47bc-d15f-345ccca638e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting my_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#chain.invoke({\"query\":\"Movie similar to Inferno\"})\n",
        "def prettyCypherChain(question: str) -> str:\n",
        "    \"\"\"Runs the cypherChain and formats the response.\"\"\"\n",
        "    response = cypherChain.run(question)\n",
        "\n",
        "    if isinstance(response, str):  # Check if response is a string\n",
        "        st.write(textwrap.fill(response, 60))\n",
        "    elif isinstance(response, dict):  # Check if response is a dictionary\n",
        "        for key, value in response.items():\n",
        "            st.write(f\"{key}: {value}\")\n",
        "    elif isinstance(response, list):  # Check if response is a list\n",
        "        # Create a DataFrame for better display in Streamlit\n",
        "        import pandas as pd\n",
        "        df = pd.DataFrame(response)\n",
        "        st.dataframe(df)\n",
        "    else:\n",
        "        st.write(response) # Print the response as is if it's not a string, dictionary, or list"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xYoAZWwF1U6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prettyCypherChain(\"Movie similar to Iron Man\")"
      ],
      "metadata": {
        "id": "oOUA3xDb71WH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run my_app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "pYu2UAonMLwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating RAG with Streamlit"
      ],
      "metadata": {
        "id": "6uZJpO9SmsJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile my_app.py\n",
        "import streamlit as st\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain.chains import GraphCypherQAChain\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from neo4j import GraphDatabase\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "import re\n",
        "from fuzzywuzzy import process\n",
        "\n",
        "# Replace with your Neo4j credentials\n",
        "import streamlit as st\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initialize Neo4j driver\n",
        "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
        "\n",
        "# Initialize LangChain Neo4jGraph integration\n",
        "kg = Neo4jGraph(uri, username, password, database)\n",
        "\n",
        "# Initialize embedding model\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Initialize memory for conversational context\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Function for cosine similarity\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
        "\n",
        "@st.cache_data\n",
        "def fetch_movie_embeddings():\n",
        "    cypher = \"\"\"\n",
        "    MATCH (m:Movie)\n",
        "    WHERE m.taglineEmbedding IS NOT NULL\n",
        "    RETURN m.id AS id, m.title AS title, m.taglineEmbedding AS embedding\n",
        "    \"\"\"\n",
        "    results = kg.query(cypher)\n",
        "    return [{\"id\": record[\"id\"], \"title\": record[\"title\"], \"embedding\": record[\"embedding\"]} for record in results]\n",
        "\n",
        "# Preprocess user query\n",
        "def preprocess_query(query):\n",
        "    stopwords = [\"recommend\", \"movie\", \"similar\", \"movies\", \"show\", \"find\", \"me\", \"please\"]\n",
        "    query = query.lower()\n",
        "    for word in stopwords:\n",
        "        query = query.replace(word, \"\")\n",
        "    query = re.sub(r'\\b\\w\\b', '', query)\n",
        "    query = re.sub(r'\\s+', ' ', query).strip()\n",
        "    query = re.sub(r'[^\\w\\s]', '', query)\n",
        "    return query\n",
        "\n",
        "# Recommend movies based on embeddings\n",
        "@st.cache_data\n",
        "def recommend_movies(query, top_k=5):\n",
        "    # Fetch all movies and their embeddings\n",
        "    movies = fetch_movie_embeddings()\n",
        "    available_titles = [movie[\"title\"] for movie in movies]\n",
        "\n",
        "    # Preprocess query\n",
        "    processed_query = preprocess_query(query)\n",
        "\n",
        "    # Extract the target movie from the query\n",
        "    if \"like\" in processed_query:\n",
        "        target_movie = processed_query.split(\"like\")[-1].strip()\n",
        "        # Use fuzzy matching to find the best match\n",
        "        matched_title, similarity = process.extractOne(target_movie, available_titles)\n",
        "\n",
        "        if similarity < 80:  # Threshold for a \"good match\"\n",
        "            return [{\"title\": f\"No close matches found for '{target_movie}'. Did you mean '{matched_title}'?\", \"score\": 0.0}]\n",
        "\n",
        "        # Fetch the embedding for the matched title\n",
        "        target_embedding = next(\n",
        "            (movie[\"embedding\"] for movie in movies if movie[\"title\"] == matched_title), None\n",
        "        )\n",
        "        if not target_embedding:\n",
        "            return [{\"title\": f\"Movie '{matched_title}' not found in the database.\", \"score\": 0.0}]\n",
        "\n",
        "        # Calculate similarity with other movies\n",
        "        similarities = [\n",
        "            {\n",
        "                \"title\": movie[\"title\"],\n",
        "                \"score\": cosine_similarity(target_embedding, movie[\"embedding\"]),\n",
        "            }\n",
        "            for movie in movies if movie[\"title\"] != matched_title\n",
        "        ]\n",
        "\n",
        "        # Sort and return top recommendations\n",
        "        return sorted(similarities, key=lambda x: x[\"score\"], reverse=True)[:top_k]\n",
        "\n",
        "    else:\n",
        "        query_embedding = embedding_model.encode(processed_query).tolist()\n",
        "\n",
        "        # Calculate similarity with all movies\n",
        "        similarities = [\n",
        "            {\n",
        "                \"title\": movie[\"title\"],\n",
        "                \"score\": cosine_similarity(query_embedding, movie[\"embedding\"]),\n",
        "            }\n",
        "            for movie in movies\n",
        "        ]\n",
        "\n",
        "        return sorted(similarities, key=lambda x: x[\"score\"], reverse=True)[:top_k]\n",
        "\n",
        "# Cypher Query Generation Prompt\n",
        "CYPHER_GENERATION_TEMPLATE = \"\"\"Task: Generate Cypher statement to query a graph database.\n",
        "Instructions:\n",
        "Use only the provided relationship types and properties in the schema.\n",
        "Do not use any other relationship types or properties that are not provided.\n",
        "Schema:\n",
        "{schema}\n",
        "Note: Do not include any explanations or apologies in your responses.\n",
        "Examples:\n",
        "\n",
        "# How many people played in Top Gun?\n",
        "MATCH (m:Movie {{name:\"Top Gun\"}})<-[:ACTED_IN]-()\n",
        "RETURN count(*) AS numberOfActors\n",
        "\n",
        "# What are movies after year 2006?\n",
        "Match (m:Movie)\n",
        "where m.year > 2006\n",
        "Return m.year, m.title\n",
        "\n",
        "# Movies directed by Ridley Scott\n",
        "MATCH (d:Director)-[:DIRECTED]->(m:Movie)\n",
        "WHERE d.name = \"Ridley Scott\"\n",
        "RETURN m.title, m.year LIMIT 5\n",
        "\n",
        "# Who directed Iron Man?\n",
        "MATCH (d:Director)-[:DIRECTED]->(m:Movie)\n",
        "WHERE m.title = \"Iron Man\"\n",
        "RETURN m.year, d.name\n",
        "\n",
        "The question is:\n",
        "{question}\"\"\"\n",
        "\n",
        "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"schema\", \"question\"], template=CYPHER_GENERATION_TEMPLATE\n",
        ")\n",
        "\n",
        "# Initialize Cypher QA Chain\n",
        "chain = GraphCypherQAChain.from_llm(\n",
        "    graph=kg,\n",
        "    cypher_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\"),\n",
        "    qa_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-16k\"),\n",
        "    memory=memory,\n",
        "    verbose=True,\n",
        "    allow_dangerous_requests=True,\n",
        ")\n",
        "\n",
        "# Function to extract and update context for movies or directors\n",
        "def extract_and_update_context(query, response):\n",
        "    \"\"\"\n",
        "    Extracts relevant context (e.g., director, movie) from the query and response\n",
        "    and updates the memory.\n",
        "    \"\"\"\n",
        "    # Handle director-related responses\n",
        "    if \"directed\" in response.lower():\n",
        "        # Extract the director's name from the response\n",
        "        parts = response.split(\"directed\")\n",
        "        if len(parts) > 1:\n",
        "            director = parts[0].strip()  # Extract name before \"directed\"\n",
        "            st.session_state.memory[\"last_director\"] = director\n",
        "\n",
        "    # Handle movie recommendation queries\n",
        "    if \"recommend\" in query.lower() or \"similar\" in query.lower():\n",
        "        if \"like\" in query.lower():\n",
        "            # Extract the target movie from the query\n",
        "            target_movie = query.split(\"like\")[-1].strip()\n",
        "            st.session_state.memory[\"last_movie\"] = target_movie\n",
        "\n",
        "# Function to handle ambiguous queries\n",
        "\n",
        "def handle_context_based_query(query):\n",
        "    \"\"\"\n",
        "    Handles queries that rely on contextual memory, such as pronouns.\n",
        "    \"\"\"\n",
        "    # Handle \"like this/it\" for movies\n",
        "    if \"like this\" in query.lower() or \"like it\" in query.lower():\n",
        "        last_movie = st.session_state.memory.get(\"last_movie\", None)\n",
        "        if last_movie:\n",
        "            recommendations = recommend_movies(f\"recommend me movie like {last_movie}\")\n",
        "            return \"\\n\".join([f\"- {rec['title']} (Similarity: {rec['score']:.6f})\" for rec in recommendations])\n",
        "        else:\n",
        "            return \"I'm sorry, I don't know what you're referring to. Could you specify the movie?\"\n",
        "\n",
        "    # Handle \"from him\" for directors\n",
        "    if \"from him\" in query.lower() or \"from her\" in query.lower() or \"from them\" in query.lower():\n",
        "        last_director = st.session_state.memory.get(\"last_director\", None)\n",
        "        if last_director:\n",
        "            # Query Neo4j for movies directed by the last tracked director\n",
        "            cypher = f\"\"\"\n",
        "            MATCH (d:Director {{name: \"{last_director}\"}})-[:DIRECTED]->(m:Movie)\n",
        "            RETURN m.title AS title\n",
        "            \"\"\"\n",
        "            results = kg.query(cypher)\n",
        "            if results:\n",
        "                return \"\\n\".join([record[\"title\"] for record in results])\n",
        "            else:\n",
        "                return f\"I couldn't find any movies directed by {last_director}.\"\n",
        "        else:\n",
        "            return \"I'm sorry, I don't know who you're referring to. Could you clarify?\"\n",
        "\n",
        "    return None  # Not a context-based query\n",
        "\n",
        "# Function to handle query submission and clear input\n",
        "def handle_query():\n",
        "    \"\"\"\n",
        "    Handles user queries and updates session state with bot responses.\n",
        "    \"\"\"\n",
        "    query = st.session_state.get(\"input\", \"\").strip()  # Access user input\n",
        "    if not query:  # Proceed only if the input is not empty\n",
        "        return\n",
        "\n",
        "    # Ensure query is added only once\n",
        "    if not st.session_state.messages or st.session_state.messages[-1] != {\"role\": \"user\", \"content\": query}:\n",
        "        st.session_state.messages.append({\"role\": \"user\", \"content\": query})\n",
        "\n",
        "        # Generate bot response\n",
        "        response = handle_context_based_query(query)\n",
        "        if not response:  # If no context-based response, proceed as usual\n",
        "            with st.spinner(\"Thinking...\"):\n",
        "                response = generate_response(query)\n",
        "\n",
        "        # Extract and store context for follow-up queries\n",
        "        extract_and_update_context(query, response)\n",
        "\n",
        "        # Append bot response only once\n",
        "        if not st.session_state.messages or st.session_state.messages[-1] != {\"role\": \"bot\", \"content\": response}:\n",
        "            st.session_state.messages.append({\"role\": \"bot\", \"content\": response})\n",
        "\n",
        "    # Clear input field for next query\n",
        "    st.session_state.input = \"\"\n",
        "\n",
        "def generate_response(query):\n",
        "    \"\"\"\n",
        "    Generates a response based on the user query.\n",
        "    \"\"\"\n",
        "    if \"recommend\" in query.lower() or \"similar\" in query.lower():\n",
        "        recommendations = recommend_movies(query)\n",
        "        return \"\\n\".join([f\"- {rec['title']} (Similarity: {rec['score']:.6f})\" for rec in recommendations])\n",
        "    else:\n",
        "        try:\n",
        "            result = chain.invoke({\"query\": query})\n",
        "            generated_query = result.get(\"query\", \"No query generated.\")\n",
        "            st.code(generated_query, language=\"cypher\")\n",
        "            return result.get(\"result\", \"No results found.\")\n",
        "        except Exception as e:\n",
        "            return f\"An error occurred: {e}\"\n",
        "\n",
        "# # Streamlit UI\n",
        "# # Main Streamlit UI\n",
        "# st.title(\"🎥 Movie Chatbot with Memory\")\n",
        "# st.markdown(\"**📢 Ask questions about movies or get recommendations!**\")\n",
        "# if \"input\" not in st.session_state:\n",
        "#     st.session_state.input = \"\"  # Initialize input during the first load\n",
        "\n",
        "\n",
        "# # Initialize session state variables\n",
        "# if \"messages\" not in st.session_state:\n",
        "#     st.session_state.messages = []\n",
        "\n",
        "# if \"memory\" not in st.session_state:\n",
        "#     st.session_state.memory = {\"last_movie\": None, \"last_director\": None}\n",
        "# # Sidebar options\n",
        "# with st.sidebar:\n",
        "#     st.title(\"🎬 Options\")\n",
        "#     if st.button(\"Clear Chat History\"):\n",
        "#         st.session_state.messages = []\n",
        "#         st.experimental_rerun()\n",
        "#     st.markdown(\"**Instructions:**\\n- Ask questions like:\\n  - Who directed Interstellar?\\n  - Recommend movies like Inception.\")\n",
        "\n",
        "# # Chat input field\n",
        "# query = st.text_area(\n",
        "#     \"💬 Your Question:\",\n",
        "#     placeholder=\"Ask about movies, directors, or get recommendations...\",\n",
        "#     value=st.session_state.get(\"input\", \"\"),\n",
        "#     key=\"input\",\n",
        "#     on_change=handle_query\n",
        "# )\n",
        "\n",
        "# # Display chat history\n",
        "# st.markdown(\"### 💬 Conversation History\")\n",
        "# for message in st.session_state.messages:\n",
        "#     if message[\"role\"] == \"user\":\n",
        "#         st.markdown(f'<div style=\"text-align: right; background-color: #dcf8c6; padding: 8px; border-radius: 10px; margin: 5px;\">{message[\"content\"]}</div>', unsafe_allow_html=True)\n",
        "#     else:\n",
        "#         st.markdown(f'<div style=\"text-align: left; background-color: #f1f0f0; padding: 8px; border-radius: 10px; margin: 5px;\">{message[\"content\"]}</div>', unsafe_allow_html=True)\n",
        "\n",
        "# # Debugging information\n",
        "# with st.expander(\"🔍 Debugging Information\"):\n",
        "#     st.write(\"**Context Memory:**\", st.session_state.memory)\n",
        "# Custom CSS for background color\n",
        "def add_custom_css():\n",
        "    st.markdown(\n",
        "        \"\"\"\n",
        "        <style>\n",
        "        /* Background color for the entire app */\n",
        "        .stApp {\n",
        "            background-color: #f0f8ff;\n",
        "        }\n",
        "        /* Chat bubbles styling */\n",
        "        .chat-bubble-user {\n",
        "            text-align: right;\n",
        "            background-color: #dcf8c6;\n",
        "            padding: 8px;\n",
        "            border-radius: 10px;\n",
        "            margin: 5px;\n",
        "        }\n",
        "        .chat-bubble-bot {\n",
        "            text-align: left;\n",
        "            background-color: #f1f0f0;\n",
        "            padding: 8px;\n",
        "            border-radius: 10px;\n",
        "            margin: 5px;\n",
        "        }\n",
        "        div.stButton > button {\n",
        "    background-color: #4682b4;\n",
        "    color: white;\n",
        "    padding: 0.5rem 1rem;\n",
        "    border-radius: 5px;\n",
        "    border: none;\n",
        "    font-size: 1rem;\n",
        "    cursor: pointer;\n",
        "}\n",
        "div.stButton > button:hover {\n",
        "    background-color: #5a9bd4;\n",
        "}\n",
        "        </style>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True,\n",
        "    )\n",
        "\n",
        "# Add custom CSS\n",
        "add_custom_css()\n",
        "\n",
        "# Main Streamlit UI\n",
        "st.title(\"🎥 CineGraph: Movie Chatbot\")\n",
        "st.markdown(\"**📢 Ask questions about movies or get recommendations!**\")\n",
        "\n",
        "# Initialize session state variables\n",
        "if \"input\" not in st.session_state:\n",
        "    st.session_state.input = \"\"  # Initialize input during the first load\n",
        "\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "if \"memory\" not in st.session_state:\n",
        "    st.session_state.memory = {\"last_movie\": None, \"last_director\": None}\n",
        "\n",
        "# Sidebar options\n",
        "with st.sidebar:\n",
        "    st.title(\"🎬 Options\")\n",
        "    if st.button(\"Clear Chat History\"):\n",
        "        st.session_state.messages = []\n",
        "        st.rerun()\n",
        "    st.markdown(\"**Instructions:**\\n- Ask questions like:\\n  - Who directed Interstellar?\\n  - Recommend movies like Inception.\")\n",
        "\n",
        "# Quick Question Buttons\n",
        "st.markdown(\"### Quick Questions\")\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    if st.button(\"Who directed Interstellar?\"):\n",
        "        st.session_state.input = \"Who directed Interstellar?\"\n",
        "        handle_query()\n",
        "\n",
        "with col2:\n",
        "    if st.button(\"Recommend movies like Inception\"):\n",
        "        st.session_state.input = \"Recommend movies like Inception\"\n",
        "        handle_query()\n",
        "\n",
        "# Chat input field\n",
        "query = st.text_area(\n",
        "    \"💬 Your Question:\",\n",
        "    placeholder=\"Ask about movies, directors, or get recommendations...\",\n",
        "    value=st.session_state.get(\"input\", \"\"),\n",
        "    key=\"input\",\n",
        "    on_change=handle_query()\n",
        ")\n",
        "\n",
        "\n",
        "# Display chat history\n",
        "st.markdown(\"### 💬 Conversation History\")\n",
        "for message in reversed(st.session_state.messages):\n",
        "    if message[\"role\"] == \"user\":\n",
        "        st.markdown(\n",
        "            f'<div class=\"chat-bubble-user\">{message[\"content\"]}</div>',\n",
        "            unsafe_allow_html=True,\n",
        "        )\n",
        "    else:\n",
        "        st.markdown(\n",
        "            f'<div class=\"chat-bubble-bot\">{message[\"content\"]}</div>',\n",
        "            unsafe_allow_html=True,\n",
        "        )\n",
        "\n",
        "# Debugging information\n",
        "with st.expander(\"🔍 Debugging Information\"):\n",
        "    st.write(\"**Context Memory:**\", st.session_state.memory)\n"
      ],
      "metadata": {
        "id": "FClimY0D7Plf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run my_app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5W6kYN07r-H",
        "outputId": "a951b411-5cc4-43de-ee7a-54eff371aa98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.106.132.174\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://chubby-eels-switch.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cLWaHsL28MU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xJ8YINHwq_Fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "def query_movies_by_genre(genre_name):\n",
        "    cypher_query = \"\"\"\n",
        "    MATCH (m:Movie)-[:HAS_GENRE]->(g:Genre {name: $genre_name})\n",
        "    RETURN m.title AS title, m.description AS description,\n",
        "           m.tagline AS tagline, m.poster_path AS poster_path,\n",
        "           m.trailer_url AS trailer_url, m.keywords AS keywords\n",
        "    LIMIT 10;\n",
        "    \"\"\"\n",
        "    with driver.session() as session:\n",
        "        result = session.run(cypher_query, {\"genre_name\": genre_name})\n",
        "        return [record.data() for record in result]\n",
        "def query_movies_by_actor(actor_name):\n",
        "    cypher_query = \"\"\"\n",
        "    MATCH (a:Actor {name: $actor_name})-[:ACTED_IN]->(m:Movie)\n",
        "    RETURN m.title AS title, m.description AS description,\n",
        "           m.tagline AS tagline, m.poster_path AS poster_path,\n",
        "           m.trailer_url AS trailer_url, m.keywords AS keywords\n",
        "    LIMIT 10;\n",
        "    \"\"\"\n",
        "    with driver.session() as session:\n",
        "        result = session.run(cypher_query, {\"actor_name\": actor_name})\n",
        "        return [record.data() for record in result]\n",
        "\n",
        "def format_movie_data(movies):\n",
        "    formatted = []\n",
        "    for movie in movies:\n",
        "        formatted.append({\n",
        "            \"title\": movie[\"title\"],\n",
        "            \"description\": movie[\"description\"],\n",
        "            \"tagline\": movie.get(\"tagline\", \"No tagline available\"),\n",
        "            \"poster\": movie.get(\"poster_path\"),\n",
        "            \"trailer\": movie.get(\"trailer_url\"),\n",
        "            \"keywords\": movie.get(\"keywords\", [])\n",
        "        })\n",
        "    return formatted\n",
        "\n",
        "def generate_recommendations(movies):\n",
        "    prompt = \"Here are some movie recommendations:\\n\\n\"\n",
        "    for movie in movies:\n",
        "        prompt += f\"Title: {movie['title']}\\n\"\n",
        "        prompt += f\"Tagline: {movie['tagline']}\\n\"\n",
        "        prompt += f\"Description: {movie['description']}\\n\"\n",
        "        prompt += f\"Keywords: {', '.join(movie['keywords'])}\\n\\n\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "0dkHun2smxvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run my_app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "jYw8pg4cttZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cat my_app.py  # Ensure the content is correctly written\n",
        "!cat /content/logs.txt\n"
      ],
      "metadata": {
        "id": "xu_10dgSwDhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zGdPm6BAyhUC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOQEnKBQGD7dZIRa2OwpQVY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}